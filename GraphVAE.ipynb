{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f732f01b-2e53-4c13-93f2-2c269086dc3d",
   "metadata": {},
   "source": [
    "# GraphVAE for networks generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a401a54a-1741-490a-820d-50f5848229e4",
   "metadata": {},
   "source": [
    "### Variational Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091b8d42-3217-4b51-bc3a-d8d5a5678b1c",
   "metadata": {},
   "source": [
    "First of all let's have a brief remind on **VAE** Variational autoencoders, firstly introduced by [*D. P. Kingma and M. Welling. 'Auto-encoding variational bayes', 2014*](https://arxiv.org/pdf/1312.6114.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1394e167-ab79-469a-9ce9-4f50ef7fbc13",
   "metadata": {},
   "source": [
    "VAE is a neural network architecture belonging to the family of variational Bayesian methods.\n",
    "\n",
    "From a probabilistic point of view we want to maximize the likelyhood of our data **x** given a proper set of parameters **$\\theta$**, like in a normal MLE problem: $p_{\\theta}(x) = p(x|\\theta)$. By neglecting from the third moment upwards, we could approximate the distribution to a normal distribution $\\mathcal{N}(x|\\mu,\\sigma)$. Simple distributions like the normal ones are usually easy to maximize, however if we assume a prior over a latent space $z$ the posterior usually becomes intractable.\n",
    "\n",
    "By marginalizing over $z$ we obtain:\n",
    "\n",
    "$$p_{\\theta}(x) = \\int_{\\mathcal{Z}}{p_{\\theta}(x,z)dz} = \\int_{\\mathcal{Z}}{p_{\\theta}(x|z)p_{\\theta}(z)dz}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625612e2-6f63-430a-a354-6bc3b423bb38",
   "metadata": {},
   "source": [
    "So we may define the set of relationships between the input data and the latent space through:\n",
    "- $p_{\\theta}(z)$ the prior distribution of the latent space\n",
    "- $p_{\\theta}(x|z)$ the likelyhood\n",
    "- $p_{\\theta}(z|x)$ the posterior\n",
    "\n",
    "Using the Bayes's theorem we could get:\n",
    "\n",
    "$$p_{\\theta}(z|x) = \\frac{p_{\\theta}(x|z)p_{\\theta}(z)}{p_{\\theta}(x)}$$\n",
    "\n",
    "but the the computation is usually expensive if not intractable. However, it is possible to approximate the posterior:\n",
    "\n",
    "$$ q_{\\phi}(z|x)\\simeq p_{\\theta}(z|x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7df44d-d079-463a-9686-e4958fef9b3c",
   "metadata": {},
   "source": [
    "### Variational Graph Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c97c73-06bb-4663-b0fe-e90fff39dbe3",
   "metadata": {},
   "source": [
    "Variational Graph Autoencoders [Kingma and Welling, 2016](https://arxiv.org/pdf/1611.07308.pdf) provide a framework extension to graph for VAEs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157764c3-ced9-4330-91f5-2b345a6705c4",
   "metadata": {},
   "source": [
    "Our problem could be formalized as follows: an undirected graph $\\mathcal{G}=(\\nu, \\epsilon)$ with $N$ nodes and a features/attribute matrix $X\\in\\mathbb{R}^{N\\times C}$. An adjacency matrix $A\\in\\mathbb{R}^{N\\times N}$ with self-loops included. Assume that each node within the graph is associated to a latent variable $\\in Z$ with $Z\\in\\mathbb{R}^{N\\times F}$ and $F$ being the latent space dimension, we are interested in inferring the latent variables of nodes in the graph and decoding the edges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2a1c1a-9eb6-4b39-82aa-4edbc6696fc6",
   "metadata": {},
   "source": [
    "Similarly to VAE, VGAE consist of an **encoder** $q_{\\phi}(Z|A,X)$, a **decoder** $p_{\\theta}(A|Z)$ and a prior $p(Z)$.\n",
    "- The **encoder** tries to learn a distribution of latent variables associated with each node conditioning on the node features $X$ and $A$. One efficient option is to instantiate $q_{\\phi}(Z|A,X)$ as a graph neural network where the learnable parameters are $\\phi$. In particular, VGAE assumes a node-independent encoder so that the probabilities factorize: $$q_{\\phi}(Z|A,X) = \\prod_{i=1}^{N}q_{\\phi}(z_{i}|A,X)$$ then, by neglecting from the third moment upwards of your distribution, the problem translates into: $$q_{\\phi}(z_{i}|A,X)=\\mathcal{N}(z_{i}|\\mu_{i},diag(\\sigma_{i}^2))$$ $$\\mathbf{\\mu},\\mathbf{\\sigma} = GCN_{\\phi}(X,A)$$ Where $z_{i}, \\mu_{i},\\sigma_{i}$ are the i-th rows of the matrices $Z,\\mu$ and $\\sigma$. The mean and diagonal covariance are predicted by the encoder network, i.e. the $GCN$. For a two-layer $GCN$ we have: $$ H=\\tilde{A}\\sigma{(\\tilde{A}XW_{1})}W_{2}$$ where $H\\in\\mathbb{R}^{N\\times d_{H}}$ are the node representations (each node is associated with a size $d_{H}$ vector), $\\tilde{A}=D^{-\\frac{1}{2}}(A+I)D^{-\\frac{1}{2}}$ is the normalized adjacency matrix as described by the [original 2016 GCN paper by Kipf and Welling](https://arxiv.org/abs/1609.02907). $\\sigma$ is a pointwise nonlinearity (e.g. a ReLU) and $\\{W_{1},W_{2}\\}$ are trainable parameters containing the biases. Relying on the learned node representation, the distribution is computed as follows: $$q_{\\phi}(Z|A,X) = \\prod_{i=1}^{N}q_{\\phi}(z_{i}|A,X)$$ $$q_{\\phi}(z_{i}|A,X)=\\mathcal{N}(z_{i}|\\mu_{i},\\sigma_{i}^2I)$$ $$\\mu=MPL_{\\mu}(H)$$ $$\\log{\\sigma}=MPL_{\\sigma}{(H)}$$ Where $\\mu_{i},\\sigma_{i}$ are the i-th rows of the MPL predictions. Therefore, the set $\\phi$ of parameters consist in the set of the trainable parameters of the twp MLPs and the aforementioned GCN. We remark that the NNs underlying each Gaussian ('GNN+MLP') are very powerful so that the conditional distributions are expressive in capturing the uncertainty of latent variables and computationally cheaper than other techniques.\n",
    "- GVAEs often adopt a **prior** that remains fixed during the training. A common choice is a node-independent Gaussian as follows: $$p(Z)=\\prod_{i}^{N}{p(z_{i})}$$ $$p(z_i)=\\mathcal{N}(0,I)$$ Surely this prior can be substituted by more powerful models such as autoregressive models at the cost of more computational resources. Nevertheless, a simple prior like the one expressed before is usually the starting point to benchmark more complicated alternatives.\n",
    "- The aim of a **decoder** is to construct a probability distribution over the graph and it's features/attributes conditioned on the latent variables, $p(\\mathcal{G}|Z)$. One should always consider all the possible node permutations, each corresponding to an adjacency matrix with different rows orderings which leaves the graph unchanged: $$ p(\\mathcal{G}|Z) = \\sum_{P\\in\\prod_{\\mathcal{G}}} {p(PAP^{T},PX|Z)}$$ but we'll neglect this discussion for the moment. A simple and popular construction of the probability distribution could be: $$ p(A,X|Z)=\\prod_{i,j}p(A_{ij}|Z)\\prod_{i=1}^{N}p(x_i|Z)$$ $$p(A_{ij}|Z)=Bernoulli(\\Theta_{ij})$$ $$p(x_i|Z)=\\mathcal{N}(\\tilde{\\mu}_{i},\\tilde{\\sigma}_i)$$ Where, once again, the parameters are learned through MLPs: $$\\Theta_{ij}=MLP_{\\Theta}([z_{i}||z_j])$$ $$\\tilde{\\mu}_{i}=MLP_{\\tilde{\\mu}}(z_i)$$ $$\\tilde{\\sigma}_{i}=MLP_{\\tilde{\\sigma}}(z_i)$$\n",
    "- The **objective** of the GVAE is the evidence lower bound (ELBO): $$\\max_{\\theta,\\phi}{\\mathbb{E}_{q_{\\phi}(Z|A,X)} {[\\log{p_{\\theta}(\\mathcal{G}|Z)}} - KL(q_{\\phi}(Z|A,X)||p(Z))]}$$ where the Kullback-Leibler divergence measures the divergence between two probability distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e06a4d-4b5a-4c68-a219-79741e0c8ec0",
   "metadata": {},
   "source": [
    "## Implementing a VGAE for link prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24b0160-5ee7-436f-af6e-46bc0b6cdcd2",
   "metadata": {},
   "source": [
    "For **link prediction** the decoder is simply the dot product of the sampled latent space. This is because our aim is to approximate and adjacency matrix $A$ and the idea is that if nodes $u,v$ are similar, their representations $z_{u}, z_{v}$ should be similar as well:\n",
    "- similar nodes: $z_{u}^{T}z_{v}$ should be maximal\n",
    "- different nodes: $z_{u}^{T}z_{v}$ should be minimal\n",
    "So far we assumed that similar nodes should be connected, thats why matrix factorization $$A\\simeq\\hat{A} = Z^{T}Z$$ works as an approximation of A. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a097bba-8ef9-4c6c-a45a-7405e6c3ec35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "#Set libraries seed\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "#Set GPU device\n",
    "device = torch.device('mps')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e159a18-a965-4905-b6a9-c911c9bcf6ba",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca5ccc5-86ba-4d1b-b006-9d33c59aa162",
   "metadata": {},
   "source": [
    "We will make use of the `Cora` dataset which is contained in the `Planetoid` data laoder of `PyTorch`.\n",
    "It is one of the most pupular datasets used for node classification and link prediction and represents a network of 2708 publications, where each connection is a reference.\n",
    "Each publication is described as a binary vector of 1433 words (the the features matrix is $X\\in\\mathbb{R}^{2708\\times1433}$), where 0 and 1 indicate the absence or presence of the corrisponding word, respectively (aka *binary bag* of words). In terms of node classification, vertices can be classified in 7 different categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2885e7a2-e597-408f-8702-5260ec6c6a3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Planetoid('.', name = 'Cora')\n",
    "data = dataset[0]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68254e82-4945-40af-8ee3-f32bcf77c039",
   "metadata": {},
   "source": [
    "Where `x` is the feature matrix, `edge_index` is a `(2, num_edges)` tensor (Compressed Sparse Column format) where edges are stored column-wise. We could print other interesting quantities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "271ba95e-1320-429f-bd35-c9cf06581a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Cora()\n",
      "---------------\n",
      "Number of graphs: 1\n",
      "Number of nodes: 2708\n",
      "Number of node features: 1433\n",
      "Number of edge features: 0\n",
      "Number of edges: 10556\n",
      "Number of classes: 7\n"
     ]
    }
   ],
   "source": [
    "print(f'Dataset: {dataset}')\n",
    "print('-'*15)\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of nodes: {data.x.shape[0]}')\n",
    "print(f'Number of node features: {data.x.shape[1]}')  # o anche data.num_node_features\n",
    "print(f'Number of edge features: {data.num_edge_features}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Number of classes: {dataset.num_classes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b7b49c-6255-49f5-9d38-31756f3facc2",
   "metadata": {},
   "source": [
    "`train_mask`, `val_mask` and `test_mask` are `num_nodes` long masks applied to the dataset for the train/val/test split.\n",
    "The default split in the Cora dataset (as used in Planetoid) follows a transductive setting, which means that during training, you only have access to the training nodes and their edges and the adjacency matrix will be restricted to reflect the connections among the nodes in the training set.\n",
    "This approach mimics a semi-supervised learning setting, where you aim to generalize your model's performance on unseen nodes (validation and test sets) based on the information available in the training set.\n",
    "\n",
    "The nodes in the training set for the Cora dataset (and other datasets in PyTorch Geometric's Planetoid) are typically chosen consecutively based on the order in which they appear in the dataset. In other words, the training set consists of a contiguous block of nodes taken from the beginning of the dataset.\n",
    "\n",
    "This consecutive selection of nodes ensures that the training set forms a representative subset of the dataset, and the ordering of nodes in the dataset is preserved. It is a common practice for simplicity and consistency when working with such datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37635597-f12a-4240-bea5-94ae0172c56e",
   "metadata": {},
   "source": [
    "Now, instead of using the default split in Cora, we implement a `transform` object that normalizes input feautures and directly performs tensor device conversion and randomly splits links in a 85/5/10 division."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e97182d3-b4aa-4198-8df2-2f1e57914534",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([\n",
    "    T.NormalizeFeatures(),\n",
    "    T.ToDevice(device),\n",
    "    T.RandomLinkSplit(num_val = 0.05, num_test=0.1, is_undirected=True, split_labels=True, add_negative_train_samples=False),\n",
    "])\n",
    " #add_negative_train_samples = False -> model already performs negative sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1a2e94d4-d957-4c8f-8c35-20bd5b408b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8972.6"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.85 * 10556"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d39d6e-e012-4d41-96b2-4105322458bc",
   "metadata": {},
   "source": [
    "As we are approaching a link prediction task, it is essential for us to split out data using `T.RandomLinkSplit`  such that the training split does not include edges in validation and test splits; and the validation split does not include edges in the test split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc89229-7bea-41f8-b81f-1b5897f2ca58",
   "metadata": {},
   "source": [
    "Now we can load Cora dataset with the transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ef45d5f8-c39c-48c7-b7d9-17a4d625e6a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2708, 1433], edge_index=[2, 8976], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], pos_edge_label=[4488], pos_edge_label_index=[2, 4488])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Planetoid('.', name = 'Cora', transform=transform)\n",
    "train_data, val_data, test_data = dataset[0]\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b0a3cf-58f7-49e1-b095-800cb4e9e4b7",
   "metadata": {},
   "source": [
    "- `positive_edges` are associated in the context of link prediction to known, existing edges in the graph.\n",
    "- `negative edges` (not present in the training set) are edges that do not exist in the graph amd are typically sampled during training to create a balanced dataset for training the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a138f7eb-b3b6-46e9-8965-ab70e24b42f0",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b5be10-9da9-403c-b0b6-2a0312e85b36",
   "metadata": {},
   "source": [
    "Let's import the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2e9373e3-658d-404f-8533-8652449675fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv, VGAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba53277-c3c0-4571-aafd-09da909ae412",
   "metadata": {},
   "source": [
    "First of all we implement the encoder which should be composed of three GCN layers: 1 shared input layer, a second layer to approximate mean values $\\mu_{i}$ and a third one for the variance (actually $\\log{\\sigma}$).\n",
    "**Please note** that the architecture is quite flexible and other type of GNNs convolutions (GraphSAGE, GIN) could be therefore used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "69183b0d-df71-4733-b999-ba01d1925949",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "        super().__init__()                                  #overwrite the method of the parent class\n",
    "        self.conv1 = GCNConv(dim_in, 2 * dim_out)           #dim_in: dimension of feature space, dim_out: dimension of latent space\n",
    "        self.conv_mu = GCNConv(2 * dim_out, dim_out)\n",
    "        self.conv_logstd = GCNConv(2 * dim_out, dim_out)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv_mu(x, edge_index), self.conv_logstd(x, edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa800564-aa2b-4e3a-8336-2778f24b30b1",
   "metadata": {},
   "source": [
    "We initialize the VGAE layer with the Encoder as input. By default, the Decoder is set to be the inner product, which is actually what we need to perform link prediction. In this particular case, the VGAE pytorch implementation **does not include MLPs after the GCNs**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f50b335c-6452-4ce5-baba-8a184f711c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGAE(Encoder(dataset.num_features, 16)).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62051621-c9c8-49d8-aa64-f925e9a6d84f",
   "metadata": {},
   "source": [
    "The `.train()` function firstly computes the embedding matrix Z through `model.encode()` which despite of the name, simply does sample embeddings from the learned distribution. Secondly, the ELBO loss is computed with `model.recon_loss()` (binary crossentropy loss) and model.kl_loss(). The decoder is implicitly called by the model to calculate the cross-entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bbf1453e-5c9c-474d-8723-435a20ebdc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(train_data.x, train_data.edge_index)\n",
    "    loss = model.recon_loss(z, train_data.pos_edge_label_index) + (1/train_data.num_nodes) * model.kl_loss()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de102f1-50c7-4736-8b47-7575b5cd69b3",
   "metadata": {},
   "source": [
    "Then we could define a `test()` function which simply calls the VGAE's dedicated method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "62baf1ab-8905-454c-ba3a-cf9ac689acf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "    return model.test(z, data.pos_edge_label_index, data.neg_edge_label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f24b0be7-5c3a-4973-9b5e-3af5a263b48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 | Loss: 0.8561 | Val AUC: 0.9340 | Val AP: 0.9396\n",
      "Epoch:  50 | Loss: 0.8394 | Val AUC: 0.9326 | Val AP: 0.9405\n",
      "Epoch: 100 | Loss: 0.8353 | Val AUC: 0.9311 | Val AP: 0.9400\n",
      "Epoch: 150 | Loss: 0.8419 | Val AUC: 0.9295 | Val AP: 0.9386\n",
      "Epoch: 200 | Loss: 0.8457 | Val AUC: 0.9280 | Val AP: 0.9380\n",
      "Epoch: 250 | Loss: 0.8363 | Val AUC: 0.9256 | Val AP: 0.9362\n",
      "Epoch: 300 | Loss: 0.8261 | Val AUC: 0.9276 | Val AP: 0.9362\n",
      "Epoch: 350 | Loss: 0.8433 | Val AUC: 0.9252 | Val AP: 0.9344\n",
      "Epoch: 400 | Loss: 0.8422 | Val AUC: 0.9223 | Val AP: 0.9328\n",
      "Epoch: 450 | Loss: 0.8413 | Val AUC: 0.9203 | Val AP: 0.9311\n",
      "Epoch: 500 | Loss: 0.8302 | Val AUC: 0.9217 | Val AP: 0.9311\n",
      "Epoch: 550 | Loss: 0.8169 | Val AUC: 0.9209 | Val AP: 0.9309\n",
      "Epoch: 600 | Loss: 0.8390 | Val AUC: 0.9196 | Val AP: 0.9302\n",
      "Epoch: 650 | Loss: 0.8333 | Val AUC: 0.9201 | Val AP: 0.9302\n",
      "Epoch: 700 | Loss: 0.8314 | Val AUC: 0.9194 | Val AP: 0.9316\n",
      "Epoch: 750 | Loss: 0.8249 | Val AUC: 0.9213 | Val AP: 0.9326\n",
      "Epoch: 800 | Loss: 0.8185 | Val AUC: 0.9201 | Val AP: 0.9321\n",
      "Epoch: 850 | Loss: 0.8185 | Val AUC: 0.9185 | Val AP: 0.9304\n",
      "Epoch: 900 | Loss: 0.8207 | Val AUC: 0.9130 | Val AP: 0.9265\n",
      "Epoch: 950 | Loss: 0.8341 | Val AUC: 0.9177 | Val AP: 0.9299\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1000):\n",
    "    loss = train()\n",
    "    val_auc, val_ap = test(val_data)\n",
    "    if epoch % 50 == 0:\n",
    "        print(f'Epoch: {epoch:>3} | Loss: {loss:.4f} | Val AUC: {val_auc:.4f} | Val AP: {val_ap:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3ef990ba-21b6-4c4e-add7-536b52279a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC: 0.9324 | Test AP: 0.9331\n"
     ]
    }
   ],
   "source": [
    "test_auc, test_ap = test(test_data)\n",
    "print(f'Test AUC: {test_auc:.4f} | Test AP: {test_ap:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caeb086f-5ecb-438a-b950-552df4d9817f",
   "metadata": {},
   "source": [
    "Finally we have out approximated adjacency matrix $\\hat{A}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "76b41959-5f21-4eb2-b63f-6e1fc3677669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8928, 0.4491, 0.5277,  ..., 0.5983, 0.8111, 0.7745],\n",
       "        [0.4491, 0.9266, 0.8993,  ..., 0.5041, 0.6885, 0.6491],\n",
       "        [0.5277, 0.8993, 0.9317,  ..., 0.4956, 0.8315, 0.7850],\n",
       "        ...,\n",
       "        [0.5983, 0.5041, 0.4956,  ..., 0.8586, 0.5083, 0.5493],\n",
       "        [0.8111, 0.6885, 0.8315,  ..., 0.5083, 0.9305, 0.8997],\n",
       "        [0.7745, 0.6491, 0.7850,  ..., 0.5493, 0.8997, 0.8702]],\n",
       "       device='mps:0', grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = model.encode (test_data.x, test_data.edge_index)\n",
    "Ahat = torch.sigmoid(z @ z.T)\n",
    "Ahat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322b3025-3a8b-4066-920b-f2699c203ee4",
   "metadata": {},
   "source": [
    "Training a VGAE is fast and outputs are easily understandable, however we know that GCNs are not the most expressive layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9642df45-c755-40a2-8320-2222ef5a4f77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
