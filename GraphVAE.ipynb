{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f732f01b-2e53-4c13-93f2-2c269086dc3d",
   "metadata": {},
   "source": [
    "# GraphVAE for networks generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a401a54a-1741-490a-820d-50f5848229e4",
   "metadata": {},
   "source": [
    "### Variational Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091b8d42-3217-4b51-bc3a-d8d5a5678b1c",
   "metadata": {},
   "source": [
    "First of all let's have a brief remind on **VAE** Variational autoencoders, firstly introduced by [*D. P. Kingma and M. Welling. 'Auto-encoding variational bayes', 2014*](https://arxiv.org/pdf/1312.6114.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1394e167-ab79-469a-9ce9-4f50ef7fbc13",
   "metadata": {},
   "source": [
    "VAE is a neural network architecture belonging to the family of variational Bayesian methods.\n",
    "\n",
    "From a probabilistic point of view we want to maximize the likelyhood of our data **x** given a proper set of parameters **$\\theta$**, like in a normal MLE problem: $p_{\\theta}(x) = p(x|\\theta)$. By neglecting from the third moment upwards, we could approximate the distribution to a normal distribution $\\mathcal{N}(x|\\mu,\\sigma)$. Simple distributions like the normal ones are usually easy to maximize, however if we assume a prior over a latent space $z$ the posterior usually becomes intractable.\n",
    "\n",
    "By marginalizing over $z$ we obtain:\n",
    "\n",
    "$$p_{\\theta}(x) = \\int_{\\mathcal{Z}}{p_{\\theta}(x,z)dz} = \\int_{\\mathcal{Z}}{p_{\\theta}(x|z)p_{\\theta}(z)dz}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625612e2-6f63-430a-a354-6bc3b423bb38",
   "metadata": {},
   "source": [
    "So we may define the set of relationships between the input data and the latent space through:\n",
    "- $p_{\\theta}(z)$ the prior distribution of the latent space\n",
    "- $p_{\\theta}(x|z)$ the likelyhood\n",
    "- $p_{\\theta}(z|x)$ the posterior\n",
    "\n",
    "Using the Bayes's theorem we could get:\n",
    "\n",
    "$$p_{\\theta}(z|x) = \\frac{p_{\\theta}(x|z)p_{\\theta}(z)}{p_{\\theta}(x)}$$\n",
    "\n",
    "but the the computation is usually expensive if not intractable. However, it is possible to approximate the posterior:\n",
    "\n",
    "$$ q_{\\phi}(z|x)\\simeq p_{\\theta}(z|x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7df44d-d079-463a-9686-e4958fef9b3c",
   "metadata": {},
   "source": [
    "### Variational Graph Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c97c73-06bb-4663-b0fe-e90fff39dbe3",
   "metadata": {},
   "source": [
    "Variational Graph Autoencoders [Kingma and Welling, 2016](https://arxiv.org/pdf/1611.07308.pdf) provide a framework extension to graph for VAEs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157764c3-ced9-4330-91f5-2b345a6705c4",
   "metadata": {},
   "source": [
    "Our problem could be formalized as follows: an undirected graph $\\mathcal{G}=(\\nu, \\epsilon)$ with $N$ nodes and a features/attribute matrix $X\\in\\mathbb{R}^{N\\times C}$. An adjacency matrix $A\\in\\mathbb{R}^{N\\times N}$ with self-loops included. Assume that each node within the graph is associated to a latent variable $\\in Z$ with $Z\\in\\mathbb{R}^{N\\times F}$ and $F$ being the latent space dimension, we are interested in inferring the latent variables of nodes in the graph and decoding the edges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2a1c1a-9eb6-4b39-82aa-4edbc6696fc6",
   "metadata": {},
   "source": [
    "Similarly to VAE, VGAE consist of an **encoder** $q_{\\phi}(Z|A,X)$, a **decoder** $p_{\\theta}(A|Z)$ and a prior $p(Z)$.\n",
    "- The **encoder** tries to learn a distribution of latent variables associated with each node conditioning on the node features $X$ and $A$. One efficient option is to instantiate $q_{\\phi}(Z|A,X)$ as a graph neural network where the learnable parameters are $\\phi$. In particular, VGAE assumes a node-independent encoder so that the probabilities factorize: $$q_{\\phi}(Z|A,X) = \\prod_{i=1}^{N}q_{\\phi}(z_{i}|A,X)$$ then, by neglecting from the third moment upwards of your distribution, the problem translates into: $$q_{\\phi}(z_{i}|A,X)=\\mathcal{N}(z_{i}|\\mu_{i},diag(\\sigma_{i}^2))$$ $$\\mathbf{\\mu},\\mathbf{\\sigma} = GCN_{\\phi}(X,A)$$ Where $z_{i}, \\mu_{i},\\sigma_{i}$ are the i-th rows of the matrices $Z,\\mu$ and $\\sigma$. The mean and diagonal covariance are predicted by the encoder network, i.e. the $GCN$. For a two-layer $GCN$ we have: $$ H=\\tilde{A}\\sigma{(\\tilde{A}XW_{1})}W_{2}$$ where $H\\in\\mathbb{R}^{N\\times d_{H}}$ are the node representations (each node is associated with a size $d_{H}$ vector), $\\tilde{A}=D^{-\\frac{1}{2}}(A+I)D^{-\\frac{1}{2}}$ is the normalized adjacency matrix as described by the [original 2016 GCN paper by Kipf and Welling](https://arxiv.org/abs/1609.02907). $\\sigma$ is a pointwise nonlinearity (e.g. a ReLU) and $\\{W_{1},W_{2}\\}$ are trainable parameters containing the biases. Relying on the learned node representation, the distribution is computed as follows: $$q_{\\phi}(Z|A,X) = \\prod_{i=1}^{N}q_{\\phi}(z_{i}|A,X)$$ $$q_{\\phi}(z_{i}|A,X)=\\mathcal{N}(z_{i}|\\mu_{i},\\sigma_{i}^2I)$$ $$\\mu=MPL_{\\mu}(H)$$ $$\\log{\\sigma}=MPL_{\\sigma}{(H)}$$ Where $\\mu_{i},\\sigma_{i}$ are the i-th rows of the MPL predictions. Therefore, the set $\\phi$ of parameters consist in the set of the trainable parameters of the twp MLPs and the aforementioned GCN. We remark that the NNs underlying each Gaussian ('GNN+MLP') are very powerful so that the conditional distributions are expressive in capturing the uncertainty of latent variables and computationally cheaper than other techniques.\n",
    "- GVAEs often adopt a **prior** that remains fixed during the training. A common choice is a node-independent Gaussian as follows: $$p(Z)=\\prod_{i}^{N}{p(z_{i})}$$ $$p(z_i)=\\mathcal{N}(0,I)$$ Surely this prior can be substituted by more powerful models such as autoregressive models at the cost of more computational resources. Nevertheless, a simple prior like the one expressed before is usually the starting point to benchmark more complicated alternatives.\n",
    "- The aim of a **decoder** is to construct a probability distribution over the graph and it's features/attributes conditioned on the latent variables, $p(\\mathcal{G}|Z)$. One should always consider all the possible node permutations, each corresponding to an adjacency matrix with different rows orderings which leaves the graph unchanged: $$ p(\\mathcal{G}|Z) = \\sum_{P\\in\\prod_{\\mathcal{G}}} {p(PAP^{T},PX|Z)}$$ but we'll neglect this discussion for the moment. A simple and popular construction of the probability distribution could be: $$ p(A,X|Z)=\\prod_{i,j}p(A_{ij}|Z)\\prod_{i=1}^{N}p(x_i|Z)$$ $$p(A_{ij}|Z)=Bernoulli(\\Theta_{ij})$$ $$p(x_i|Z)=\\mathcal{N}(\\tilde{\\mu}_{i},\\tilde{\\sigma}_i)$$ Where, once again, the parameters are learned through MLPs: $$\\Theta_{ij}=MLP_{\\Theta}([z_{i}||z_j])$$ $$\\tilde{\\mu}_{i}=MLP_{\\tilde{\\mu}}(z_i)$$ $$\\tilde{\\sigma}_{i}=MLP_{\\tilde{\\sigma}}(z_i)$$\n",
    "- The **objective** of the GVAE is the evidence lower bound (ELBO): $$\\max_{\\theta,\\phi}{\\mathbb{E}_{q_{\\phi}(Z|A,X)} {[\\log{p_{\\theta}(\\mathcal{G}|Z)}} - KL(q_{\\phi}(Z|A,X)||p(Z))]}$$ where the Kullback-Leibler divergence measures the divergence between two probability distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e06a4d-4b5a-4c68-a219-79741e0c8ec0",
   "metadata": {},
   "source": [
    "## Implementing a VGAE for link prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24b0160-5ee7-436f-af6e-46bc0b6cdcd2",
   "metadata": {},
   "source": [
    "For **link prediction** the decoder is simply the dot product of the sampled latent space. This is because our aim is to approximate and adjacency matrix $A$ and the idea is that if nodes $u,v$ are similar, their representations $z_{u}, z_{v}$ should be similar as well:\n",
    "- similar nodes: $z_{u}^{T}z_{v}$ should be maximal\n",
    "- different nodes: $z_{u}^{T}z_{v}$ should be minimal\n",
    "So far we assumed that similar nodes should be connected, thats why matrix factorization $$A\\simeq\\hat{A} = Z^{T}Z$$ works as an approximation of A.\n",
    "\n",
    "As we want the elements of $\\hat{A}$ to be as similar as possible to the ones of $A$, part of the objective is then a measure of how well the model reconstructs the original matrix and is computed through a **binary cross entropy loss**. We will call it *reconstruction term* $\\mathcal{L}_{rec}$: $$ \\mathcal{L_rec} = \\sum_{i,j \\in V} {-A_{ij}\\log{\\hat{A}_{ij}} - (1-A_{ij})\\log{(1-\\hat{A_{ij}})}}$$\n",
    "\n",
    "The second term that forms the objective of this task is a regularization term used in variational autoencoders to promote the latent space to follow a specific distribution, usually a normal distribution $z\\sim\\mathcal{N}(0,\\mathbb{I})$. As a matter of facts, the KL-divergence measures the divergence between the learned distribution of the latent variables and target distribution and we will call this term $\\mathcal{L}_{KL}$: \n",
    "\n",
    "$$\\mathcal{L}_{KL}=KL(q_{\\phi}(Z|A)||p(Z)) = \\frac{1}{2}\\sum_{i}{(1+\\log{\\sigma_{i}^{2}}-\\mu_{i}^{2}-\\sigma_{i}^{2})}$$\n",
    "\n",
    "Where $\\mu, \\sigma$ are the encoder's output. The total loss, called *evidence lower bound (ELBO)* loss is therefore: $$\\mathcal{L}_{ELBO} = \\mathcal{L}_{rec} - \\mathcal{L}_{KL}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a097bba-8ef9-4c6c-a45a-7405e6c3ec35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "#Set libraries seed\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "#Set GPU device\n",
    "device = torch.device('mps')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e159a18-a965-4905-b6a9-c911c9bcf6ba",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca5ccc5-86ba-4d1b-b006-9d33c59aa162",
   "metadata": {},
   "source": [
    "We will make use of the `Cora` dataset which is contained in the `Planetoid` data laoder of `PyTorch`.\n",
    "It is one of the most pupular datasets used for node classification and link prediction and represents a network of 2708 publications, where each connection is a reference.\n",
    "Each publication is described as a binary vector of 1433 words (the the features matrix is $X\\in\\mathbb{R}^{2708\\times1433}$), where 0 and 1 indicate the absence or presence of the corrisponding word, respectively (aka *binary bag* of words). In terms of node classification, vertices can be classified in 7 different categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2885e7a2-e597-408f-8702-5260ec6c6a3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Planetoid('.', name = 'Cora')\n",
    "data = dataset[0]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68254e82-4945-40af-8ee3-f32bcf77c039",
   "metadata": {},
   "source": [
    "Where `x` is the feature matrix, `edge_index` is a `(2, num_edges)` tensor (Compressed Sparse Column format) where edges are stored column-wise. We could print other interesting quantities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "271ba95e-1320-429f-bd35-c9cf06581a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Cora()\n",
      "---------------\n",
      "Number of graphs: 1\n",
      "Number of nodes: 2708\n",
      "Number of node features: 1433\n",
      "Number of edge features: 0\n",
      "Number of edges: 10556\n",
      "Number of classes: 7\n"
     ]
    }
   ],
   "source": [
    "print(f'Dataset: {dataset}')\n",
    "print('-'*15)\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of nodes: {data.x.shape[0]}')\n",
    "print(f'Number of node features: {data.x.shape[1]}')  # o anche data.num_node_features\n",
    "print(f'Number of edge features: {data.num_edge_features}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Number of classes: {dataset.num_classes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b7b49c-6255-49f5-9d38-31756f3facc2",
   "metadata": {},
   "source": [
    "`train_mask`, `val_mask` and `test_mask` are `num_nodes` long masks applied to the dataset for the train/val/test split.\n",
    "The default split in the Cora dataset (as used in Planetoid) follows a transductive setting, which means that during training, you only have access to the training nodes and their edges and the adjacency matrix will be restricted to reflect the connections among the nodes in the training set.\n",
    "This approach mimics a semi-supervised learning setting, where you aim to generalize your model's performance on unseen nodes (validation and test sets) based on the information available in the training set.\n",
    "\n",
    "The nodes in the training set for the Cora dataset (and other datasets in PyTorch Geometric's Planetoid) are typically chosen consecutively based on the order in which they appear in the dataset. In other words, the training set consists of a contiguous block of nodes taken from the beginning of the dataset.\n",
    "\n",
    "This consecutive selection of nodes ensures that the training set forms a representative subset of the dataset, and the ordering of nodes in the dataset is preserved. It is a common practice for simplicity and consistency when working with such datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37635597-f12a-4240-bea5-94ae0172c56e",
   "metadata": {},
   "source": [
    "Now, instead of using the default split in Cora, we implement a `transform` object that normalizes input feautures and directly performs tensor device conversion and randomly splits links in a 85/5/10 division."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e97182d3-b4aa-4198-8df2-2f1e57914534",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([\n",
    "    T.NormalizeFeatures(),\n",
    "    T.ToDevice(device),\n",
    "    T.RandomLinkSplit(num_val = 0.05, num_test=0.1, is_undirected=True, split_labels=True, add_negative_train_samples=False),\n",
    "])\n",
    " #add_negative_train_samples = False -> model already performs negative sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d39d6e-e012-4d41-96b2-4105322458bc",
   "metadata": {},
   "source": [
    "As we are approaching a link prediction task, it is essential for us to split out data using `T.RandomLinkSplit`  such that the training split does not include edges in validation and test splits; and the validation split does not include edges in the test split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc89229-7bea-41f8-b81f-1b5897f2ca58",
   "metadata": {},
   "source": [
    "Now we can load Cora dataset with the transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef45d5f8-c39c-48c7-b7d9-17a4d625e6a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2708, 1433], edge_index=[2, 8976], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], pos_edge_label=[4488], pos_edge_label_index=[2, 4488])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Planetoid('.', name = 'Cora', transform=transform)\n",
    "train_data, val_data, test_data = dataset[0]\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b0a3cf-58f7-49e1-b095-800cb4e9e4b7",
   "metadata": {},
   "source": [
    "- `positive_edges` are associated in the context of link prediction to known, existing edges in the graph.\n",
    "- `negative edges` (not present in the training set) are edges that do not exist in the graph amd are typically sampled during training to create a balanced dataset for training the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a138f7eb-b3b6-46e9-8965-ab70e24b42f0",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b5be10-9da9-403c-b0b6-2a0312e85b36",
   "metadata": {},
   "source": [
    "Let's import the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e9373e3-658d-404f-8533-8652449675fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv, VGAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba53277-c3c0-4571-aafd-09da909ae412",
   "metadata": {},
   "source": [
    "First of all we implement the encoder which should be composed of three GCN layers: 1 shared input layer, a second layer to approximate mean values $\\mu_{i}$ and a third one for the variance (actually $\\log{\\sigma}$).\n",
    "**Please note** that the architecture is quite flexible and other type of GNNs convolutions (GraphSAGE, GIN) could be therefore used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69183b0d-df71-4733-b999-ba01d1925949",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "        super().__init__()                                  #overwrite the method of the parent class\n",
    "        self.conv1 = GCNConv(dim_in, 2 * dim_out)           #dim_in: dimension of feature space, dim_out: dimension of latent space\n",
    "        self.conv_mu = GCNConv(2 * dim_out, dim_out)\n",
    "        self.conv_logstd = GCNConv(2 * dim_out, dim_out)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv_mu(x, edge_index), self.conv_logstd(x, edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa800564-aa2b-4e3a-8336-2778f24b30b1",
   "metadata": {},
   "source": [
    "We initialize the VGAE layer with the Encoder as input. By default, the Decoder is set to be the inner product, which is actually what we need to perform link prediction. In this particular case, the VGAE pytorch implementation **does not include MLPs after the GCNs**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f50b335c-6452-4ce5-baba-8a184f711c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGAE(\n",
       "  (encoder): Encoder(\n",
       "    (conv1): GCNConv(1433, 32)\n",
       "    (conv_mu): GCNConv(32, 16)\n",
       "    (conv_logstd): GCNConv(32, 16)\n",
       "  )\n",
       "  (decoder): InnerProductDecoder()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VGAE(Encoder(dataset.num_features, 16)).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62051621-c9c8-49d8-aa64-f925e9a6d84f",
   "metadata": {},
   "source": [
    "The `.train()` function firstly computes the embedding matrix Z through `model.encode()` which despite of the name, simply samples embeddings from the learned distribution. Secondly, the ELBO loss is computed with `model.recon_loss()` (binary crossentropy loss, what we called $\\mathcal{L}_{rec}$) and model.kl_loss(), the $\\mathcal{L}_{KL}$ loss. The decoder is implicitly called by the model to calculate the cross-entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbf1453e-5c9c-474d-8723-435a20ebdc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(train_data.x, train_data.edge_index)\n",
    "    loss = model.recon_loss(z, train_data.pos_edge_label_index) + (1/train_data.num_nodes) * model.kl_loss()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa46dcbd-ff62-4cd6-9927-17505d8ecdc4",
   "metadata": {},
   "source": [
    "**Negative sampling**:\n",
    "\n",
    "*positive edges* are edges that actually exist in my graph while *negative edges* are artificially created edges that are not present in the original graph. During training the model is presented the positive edges and it is instructed to learn to predict their existence by adjusting its parameters to minimize the prediction error.\n",
    "\n",
    "During evaluation, to assess the model's performance, we create negative edges by sampling pairs of node that were not connected in the original graph and we mix them with the positive known edges to form a test set for evaluation. The model task during evaluation is to distinguish between true edges and fake ones.\n",
    "\n",
    "To this purpose, we use metrics like area under the ROC curve (**AUC**) and average precision (**AP**) by putting a 0.5 threshold to our newly generated approximation of the adjacency matrix $\\hat{A}$ and counting the correct prediction over the negative and positive edges set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de102f1-50c7-4736-8b47-7575b5cd69b3",
   "metadata": {},
   "source": [
    "Then we could define a `test()` function which simply calls the VGAE's dedicated method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62baf1ab-8905-454c-ba3a-cf9ac689acf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()       #explicitly states that this function should be executed without gradient tracking\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "    return model.test(z, data.pos_edge_label_index, data.neg_edge_label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f24b0be7-5c3a-4973-9b5e-3af5a263b48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 | Loss: 3.4849 | Val AUC: 0.6796 | Val AP: 0.7303\n",
      "Epoch:  50 | Loss: 1.3280 | Val AUC: 0.6666 | Val AP: 0.7179\n",
      "Epoch: 100 | Loss: 1.2012 | Val AUC: 0.7703 | Val AP: 0.7827\n",
      "Epoch: 150 | Loss: 1.1269 | Val AUC: 0.7861 | Val AP: 0.7945\n",
      "Epoch: 200 | Loss: 1.0276 | Val AUC: 0.8350 | Val AP: 0.8313\n",
      "Epoch: 250 | Loss: 0.9941 | Val AUC: 0.8578 | Val AP: 0.8556\n",
      "Epoch: 300 | Loss: 0.9425 | Val AUC: 0.8904 | Val AP: 0.8891\n",
      "Epoch: 350 | Loss: 0.9346 | Val AUC: 0.8961 | Val AP: 0.8992\n",
      "Epoch: 400 | Loss: 0.9130 | Val AUC: 0.9004 | Val AP: 0.9066\n",
      "Epoch: 450 | Loss: 0.9070 | Val AUC: 0.8943 | Val AP: 0.9059\n",
      "Epoch: 500 | Loss: 0.9018 | Val AUC: 0.9038 | Val AP: 0.9157\n",
      "Epoch: 550 | Loss: 0.8947 | Val AUC: 0.9028 | Val AP: 0.9144\n",
      "Epoch: 600 | Loss: 0.8986 | Val AUC: 0.9015 | Val AP: 0.9136\n",
      "Epoch: 650 | Loss: 0.8860 | Val AUC: 0.8965 | Val AP: 0.9109\n",
      "Epoch: 700 | Loss: 0.8897 | Val AUC: 0.9011 | Val AP: 0.9135\n",
      "Epoch: 750 | Loss: 0.8843 | Val AUC: 0.9033 | Val AP: 0.9164\n",
      "Epoch: 800 | Loss: 0.8868 | Val AUC: 0.9065 | Val AP: 0.9182\n",
      "Epoch: 850 | Loss: 0.8647 | Val AUC: 0.9083 | Val AP: 0.9205\n",
      "Epoch: 900 | Loss: 0.8677 | Val AUC: 0.9097 | Val AP: 0.9216\n",
      "Epoch: 950 | Loss: 0.8775 | Val AUC: 0.9089 | Val AP: 0.9207\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1000):\n",
    "    loss = train()\n",
    "    val_auc, val_ap = test(val_data)\n",
    "    if epoch % 50 == 0:\n",
    "        print(f'Epoch: {epoch:>3} | Loss: {loss:.4f} | Val AUC: {val_auc:.4f} | Val AP: {val_ap:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ef990ba-21b6-4c4e-add7-536b52279a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC: 0.9124 | Test AP: 0.9160\n"
     ]
    }
   ],
   "source": [
    "test_auc, test_ap = test(test_data)\n",
    "print(f'Test AUC: {test_auc:.4f} | Test AP: {test_ap:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caeb086f-5ecb-438a-b950-552df4d9817f",
   "metadata": {},
   "source": [
    "Finally we have out approximated adjacency matrix $\\hat{A}$ for the `test_data` portion of nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76b41959-5f21-4eb2-b63f-6e1fc3677669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9463, 0.5546, 0.6930,  ..., 0.6464, 0.7617, 0.7717],\n",
       "        [0.5546, 0.9301, 0.9180,  ..., 0.2188, 0.5944, 0.5480],\n",
       "        [0.6930, 0.9180, 0.9482,  ..., 0.1936, 0.8068, 0.7456],\n",
       "        ...,\n",
       "        [0.6464, 0.2188, 0.1936,  ..., 0.8876, 0.3795, 0.4563],\n",
       "        [0.7617, 0.5944, 0.8068,  ..., 0.3795, 0.8707, 0.8264],\n",
       "        [0.7717, 0.5480, 0.7456,  ..., 0.4563, 0.8264, 0.7933]],\n",
       "       device='mps:0', grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = model.encode (test_data.x, test_data.edge_index)\n",
    "Ahat = torch.sigmoid(z @ z.T)\n",
    "Ahat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322b3025-3a8b-4066-920b-f2699c203ee4",
   "metadata": {},
   "source": [
    "Training a VGAE is fast and outputs are easily understandable, however we know that GCNs are not the most expressive layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e334d55-53f2-4c1a-87ad-3ba660d64c25",
   "metadata": {},
   "source": [
    "## Implementing a GraphVAE for graph generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595a7639-5953-4c61-9075-5b80d0814b96",
   "metadata": {},
   "source": [
    "In a **graph generation** task we need to specialize our **encoder** to a feed-forward neural network with edge-conditional graph convolutions (ECC) and the **decoder** to a MLP with three outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b396e8-5536-42a7-9ec9-d225cd2c9f35",
   "metadata": {},
   "source": [
    "The problem consists in having a graph $G=(A,E,F)$ with A adj matrix, E edge attribute tensor and F node attribute matrix. Once again, we will assume a normal prior $p(z)=\\mathcal{N}(0,\\mathbb{I})$ and the whole model (encoder $\\rightarrow$ prior sampling $\\rightarrow$ decoder) is trained using: \n",
    "$$ \\mathcal{L}_{\\theta,\\phi;G} = \\mathbb{E}_{q_{\\phi}(z|G)} [-\\log{p_{\\theta}(G|z)}] + KL[q_{\\phi}(z|G)||p(z)] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874bca8b-138d-4a77-a255-806d42bb45b8",
   "metadata": {},
   "source": [
    "The decoder itself is a deterministic MLP with three output in the last layer. Sigmoid activation function is used to compute $\\hat{A}$, whereas edge- and node-wise softmax is applied to obtain $\\hat{E}$ and $\\hat{F}$, respectively. The actual formulation of the loss should consider permutation caveats that we wont discuss here. The following implementation was proposed by [*J. You et al.*](https://github.com/JiaxuanYou/graph-generation/tree/master) as a baseline model for comparison with their newly introduced GraphRNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "16e4117d-f4d7-44ef-8e54-76bb9ab485c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ee67fa21-ec85-4601-827b-8377fc681f90",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected ':' (2521976885.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[36], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    class GraphVAE(torch.nn.Module)\u001b[0m\n\u001b[0m                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m expected ':'\n"
     ]
    }
   ],
   "source": [
    "class GraphVAE(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim, max_num_nodes, pool='sum'):\n",
    "        \n",
    "        '''\n",
    "        Args:\n",
    "            input_dim: input feature dimension for node.\n",
    "            hidden_dim: hidden dim for 2-layer gcn.\n",
    "            latent_dim: dimension of the latent representation of graph.\n",
    "        '''\n",
    "\n",
    "        super().__init()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(input_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(input_dim)\n",
    "        self.act = torch.nn.Relu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3357a2aa-dd7c-43dc-a1e6-02b1f0c71fd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
