{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f732f01b-2e53-4c13-93f2-2c269086dc3d",
   "metadata": {},
   "source": [
    "# GraphVAE for networks generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a401a54a-1741-490a-820d-50f5848229e4",
   "metadata": {},
   "source": [
    "### Variational Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091b8d42-3217-4b51-bc3a-d8d5a5678b1c",
   "metadata": {},
   "source": [
    "First of all let's have a brief remind on **VAE** Variational autoencoders, firstly introduced by [*D. P. Kingma and M. Welling. 'Auto-encoding variational bayes', 2014*](https://arxiv.org/pdf/1312.6114.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1394e167-ab79-469a-9ce9-4f50ef7fbc13",
   "metadata": {},
   "source": [
    "VAE is a neural network architecture belonging to the family of variational Bayesian methods.\n",
    "\n",
    "From a probabilistic point of view we want to maximize the likelyhood of our data **x** given a proper set of parameters **$\\theta$**, like in a normal MLE problem: $p_{\\theta}(x) = p(x|\\theta)$. By neglecting from the third moment upwards, we could approximate the distribution to a normal distribution $\\mathcal{N}(x|\\mu,\\sigma)$. Simple distributions like the normal ones are usually easy to maximize, however if we assume a prior over a latent space $z$ the posterior usually becomes intractable.\n",
    "\n",
    "By marginalizing over $z$ we obtain:\n",
    "\n",
    "$$p_{\\theta}(x) = \\int_{\\mathcal{Z}}{p_{\\theta}(x,z)dz} = \\int_{\\mathcal{Z}}{p_{\\theta}(x|z)p_{\\theta}(z)dz}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625612e2-6f63-430a-a354-6bc3b423bb38",
   "metadata": {},
   "source": [
    "So we may define the set of relationships between the input data and the latent space through:\n",
    "- $p_{\\theta}(z)$ the prior distribution of the latent space\n",
    "- $p_{\\theta}(x|z)$ the likelyhood\n",
    "- $p_{\\theta}(z|x)$ the posterior\n",
    "\n",
    "Using the Bayes's theorem we could get:\n",
    "\n",
    "$$p_{\\theta}(z|x) = \\frac{p_{\\theta}(x|z)p_{\\theta}(z)}{p_{\\theta}(x)}$$\n",
    "\n",
    "but the the computation is usually expensive if not intractable. However, it is possible to approximate the posterior:\n",
    "\n",
    "$$ q_{\\phi}(z|x)\\simeq p_{\\theta}(z|x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7df44d-d079-463a-9686-e4958fef9b3c",
   "metadata": {},
   "source": [
    "### Variational Graph Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c97c73-06bb-4663-b0fe-e90fff39dbe3",
   "metadata": {},
   "source": [
    "Variational Graph Autoencoders [Kingma and Welling, 2016](https://arxiv.org/pdf/1611.07308.pdf) provide a framework extension to graph for VAEs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157764c3-ced9-4330-91f5-2b345a6705c4",
   "metadata": {},
   "source": [
    "Our problem could be formalized as follows: an undirected graph $\\mathcal{G}=(\\nu, \\epsilon)$ with $N$ nodes and a features/attribute matrix $X\\in\\mathbb{R}^{N\\times C}$. An adjacency matrix $A\\in\\mathbb{R}^{N\\times N}$ with self-loops included. Assume that each node within the graph is associated to a latent variable $\\in Z$ with $Z\\in\\mathbb{R}^{N\\times F}$ and $F$ being the latent space dimension, we are interested in inferring the latent variables of nodes in the graph and decoding the edges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2a1c1a-9eb6-4b39-82aa-4edbc6696fc6",
   "metadata": {},
   "source": [
    "Similarly to VAE, VGAE consist of an **encoder** $q_{\\phi}(Z|A,X)$, a **decoder** $p_{\\theta}(A|Z)$ and a prior $p(Z)$.\n",
    "- The **encoder** tries to learn a distribution of latent variables associated with each node conditioning on the node features $X$ and $A$. One efficient option is to instantiate $q_{\\phi}(Z|A,X)$ as a graph neural network where the learnable parameters are $\\phi$. In particular, VGAE assumes a node-independent encoder so that the probabilities factorize: $$q_{\\phi}(Z|A,X) = \\prod_{i=1}^{N}q_{\\phi}(z_{i}|A,X)$$ then, by neglecting from the third moment upwards of your distribution, the problem translates into: $$q_{\\phi}(z_{i}|A,X)=\\mathcal{N}(z_{i}|\\mu_{i},diag(\\sigma_{i}^2))$$ $$\\mathbf{\\mu},\\mathbf{\\sigma} = GCN_{\\phi}(X,A)$$ Where $z_{i}, \\mu_{i},\\sigma_{i}$ are the i-th rows of the matrices $Z,\\mu$ and $\\sigma$. The mean and diagonal covariance are predicted by the encoder network, i.e. the $GCN$. For a two-layer $GCN$ we have: $$ H=\\tilde{A}\\sigma{(\\tilde{A}XW_{1})}W_{2}$$ where $H\\in\\mathbb{R}^{N\\times d_{H}}$ are the node representations (each node is associated with a size $d_{H}$ vector), $\\tilde{A}=D^{-\\frac{1}{2}}(A+I)D^{-\\frac{1}{2}}$ is the normalized adjacency matrix as described by the [original 2016 GCN paper by Kipf and Welling](https://arxiv.org/abs/1609.02907). $\\sigma$ is a pointwise nonlinearity (e.g. a ReLU) and $\\{W_{1},W_{2}\\}$ are trainable parameters containing the biases. Relying on the learned node representation, the distribution is computed as follows: $$q_{\\phi}(Z|A,X) = \\prod_{i=1}^{N}q_{\\phi}(z_{i}|A,X)$$ $$q_{\\phi}(z_{i}|A,X)=\\mathcal{N}(z_{i}|\\mu_{i},\\sigma_{i}^2I)$$ $$\\mu=MPL_{\\mu}(H)$$ $$\\log{\\sigma}=MPL_{\\sigma}{(H)}$$ Where $\\mu_{i},\\sigma_{i}$ are the i-th rows of the MPL predictions. Therefore, the set $\\phi$ of parameters consist in the set of the trainable parameters of the twp MLPs and the aforementioned GCN. We remark that the NNs underlying each Gaussian ('GNN+MLP') are very powerful so that the conditional distributions are expressive in capturing the uncertainty of latent variables and computationally cheaper than other techniques.\n",
    "- GVAEs often adopt a **prior** that remains fixed during the training. A common choice is a node-independent Gaussian as follows: $$p(Z)=\\prod_{i}^{N}{p(z_{i})}$$ $$p(z_i)=\\mathcal{N}(0,I)$$ Surely this prior can be substituted by more powerful models such as autoregressive models at the cost of more computational resources. Nevertheless, a simple prior like the one expressed before is usually the starting point to benchmark more complicated alternatives.\n",
    "- The aim of a **decoder** is to construct a probability distribution over the graph and it's features/attributes conditioned on the latent variables, $p(\\mathcal{G}|Z)$. One should always consider all the possible node permutations, each corresponding to an adjacency matrix with different rows orderings which leaves the graph unchanged: $$ p(\\mathcal{G}|Z) = \\sum_{P\\in\\prod_{\\mathcal{G}}} {p(PAP^{T},PX|Z)}$$ but we'll neglect this discussion for the moment. A simple and popular construction of the probability distribution could be: $$ p(A,X|Z)=\\prod_{i,j}p(A_{ij}|Z)\\prod_{i=1}^{N}p(x_i|Z)$$ $$p(A_{ij}|Z)=Bernoulli(\\Theta_{ij})$$ $$p(x_i|Z)=\\mathcal{N}(\\tilde{\\mu}_{i},\\tilde{\\sigma}_i)$$ Where, once again, the parameters are learned through MLPs: $$\\Theta_{ij}=MLP_{\\Theta}([z_{i}||z_j])$$ $$\\tilde{\\mu}_{i}=MLP_{\\tilde{\\mu}}(z_i)$$ $$\\tilde{\\sigma}_{i}=MLP_{\\tilde{\\sigma}}(z_i)$$\n",
    "- The **objective** of the GVAE is the evidence lower bound (ELBO): $$\\max_{\\theta,\\phi}{\\mathbb{E}_{q_{\\phi}(Z|A,X)} {[\\log{p_{\\theta}(\\mathcal{G}|Z)}} - KL(q_{\\phi}(Z|A,X)||p(Z))]}$$ where the Kullback-Leibler divergence measures the divergence between two probability distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e06a4d-4b5a-4c68-a219-79741e0c8ec0",
   "metadata": {},
   "source": [
    "## Implementing a VGAE for link prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a097bba-8ef9-4c6c-a45a-7405e6c3ec35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "#Set libraries seed\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "#Set GPU device\n",
    "device = torch.device('mps')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37635597-f12a-4240-bea5-94ae0172c56e",
   "metadata": {},
   "source": [
    "Firstly we implement a `transform` object that normalizes input feautures and directly performs tensor device conversion and randomly splits links in a 85/5/10 division."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e97182d3-b4aa-4198-8df2-2f1e57914534",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([\n",
    "    T.NormalizeFeatures(),\n",
    "    T.ToDevice(device),\n",
    "    T.RandomLinkSplit(num_val = 0.05, num_test=0.1, is_undirected=True, split_labels=True, add_negative_train_samples=False),\n",
    "])\n",
    " #add_negative_train_samples = False -> model already performs negative sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc89229-7bea-41f8-b81f-1b5897f2ca58",
   "metadata": {},
   "source": [
    "Load Cora dataset with the transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ef45d5f8-c39c-48c7-b7d9-17a4d625e6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Planetoid('.', name = 'Cora', transform=transform)\n",
    "train_data, val_data, test_data = dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b5be10-9da9-403c-b0b6-2a0312e85b36",
   "metadata": {},
   "source": [
    "Let's import the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2e9373e3-658d-404f-8533-8652449675fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv, VGAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba53277-c3c0-4571-aafd-09da909ae412",
   "metadata": {},
   "source": [
    "First of all we implement the encoder which should be composed of three GCN layers: 1 shared input layer, a second layer to approximate mean values $\\mu_{i}$ and a third one for the variance (actually $\\log{\\sigma}$):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "69183b0d-df71-4733-b999-ba01d1925949",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "        super().__init__()                 #overwrite the method of the parent class\n",
    "        self.conv1 = GCNConv(dim_in, 2 * dim_out)\n",
    "        self.conv_mu = GCNConv(2 * dim_out, dim_out)\n",
    "        self.conv_logstd = GCNConv(2 * dim_out, dim_out)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv_mu(x, edge_index), self.conv_logstd(x, edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa800564-aa2b-4e3a-8336-2778f24b30b1",
   "metadata": {},
   "source": [
    "We initialize the VGAE layer with the Encoder as input. By default, the Decoder is set to be the inner product, which is actually what we need to perform link prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f50b335c-6452-4ce5-baba-8a184f711c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGAE(Encoder(dataset.num_features, 16)).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62051621-c9c8-49d8-aa64-f925e9a6d84f",
   "metadata": {},
   "source": [
    "The `.train()` function firstly computes the embedding matrix Z through `model.encode()` which despite of the name, simply does sample embeddings from the learned distribution. Secondly, the ELBO loss is computed with `model.recon_loss()` (binary crossentropy loss) and model.kl_loss(). The decoder is implicitly called by the model to calculate the cross-entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bbf1453e-5c9c-474d-8723-435a20ebdc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(train_data.x, train_data.edge_index)\n",
    "    loss = model.recon_loss(z, train_data.pos_edge_label_index) + (1/train_data.num_nodes) * model.kl_loss()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de102f1-50c7-4736-8b47-7575b5cd69b3",
   "metadata": {},
   "source": [
    "Then we could define a `test()` function which simply calls the VGAE's dedicated method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "62baf1ab-8905-454c-ba3a-cf9ac689acf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "    return model.test(z, data.pos_edge_label_index, data.neg_edge_label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f24b0be7-5c3a-4973-9b5e-3af5a263b48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 0.9460 | Val AUC: 0.8824 | Val AP: 0.8861\n",
      "Epoch: 50 | Loss: 0.9071 | Val AUC: 0.8840 | Val AP: 0.8885\n",
      "Epoch: 100 | Loss: 0.9188 | Val AUC: 0.8934 | Val AP: 0.8956\n",
      "Epoch: 150 | Loss: 0.8944 | Val AUC: 0.8985 | Val AP: 0.8996\n",
      "Epoch: 200 | Loss: 0.8903 | Val AUC: 0.9020 | Val AP: 0.9065\n",
      "Epoch: 250 | Loss: 0.8860 | Val AUC: 0.9052 | Val AP: 0.9110\n",
      "Epoch: 300 | Loss: 0.8736 | Val AUC: 0.8987 | Val AP: 0.9071\n",
      "Epoch: 350 | Loss: 0.8747 | Val AUC: 0.8993 | Val AP: 0.9069\n",
      "Epoch: 400 | Loss: 0.8747 | Val AUC: 0.8976 | Val AP: 0.9047\n",
      "Epoch: 450 | Loss: 0.8688 | Val AUC: 0.8961 | Val AP: 0.9046\n",
      "Epoch: 500 | Loss: 0.8606 | Val AUC: 0.8957 | Val AP: 0.9058\n",
      "Epoch: 550 | Loss: 0.8534 | Val AUC: 0.8920 | Val AP: 0.9031\n",
      "Epoch: 600 | Loss: 0.8703 | Val AUC: 0.8914 | Val AP: 0.9035\n",
      "Epoch: 650 | Loss: 0.8496 | Val AUC: 0.8985 | Val AP: 0.9087\n",
      "Epoch: 700 | Loss: 0.8500 | Val AUC: 0.8975 | Val AP: 0.9090\n",
      "Epoch: 750 | Loss: 0.8537 | Val AUC: 0.8977 | Val AP: 0.9099\n",
      "Epoch: 800 | Loss: 0.8514 | Val AUC: 0.9017 | Val AP: 0.9106\n",
      "Epoch: 850 | Loss: 0.8621 | Val AUC: 0.9030 | Val AP: 0.9127\n",
      "Epoch: 900 | Loss: 0.8505 | Val AUC: 0.9042 | Val AP: 0.9138\n",
      "Epoch: 950 | Loss: 0.8516 | Val AUC: 0.9023 | Val AP: 0.9126\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1000):\n",
    "    loss = train()\n",
    "    val_auc, val_ap = test(val_data)\n",
    "    if epoch % 50 == 0:\n",
    "        print(f'Epoch: {epoch} | Loss: {loss:.4f} | Val AUC: {val_auc:.4f} | Val AP: {val_ap:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3ef990ba-21b6-4c4e-add7-536b52279a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC: 0.9324 | Test AP: 0.9331\n"
     ]
    }
   ],
   "source": [
    "test_auc, test_ap = test(test_data)\n",
    "print(f'Test AUC: {test_auc:.4f} | Test AP: {test_ap:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caeb086f-5ecb-438a-b950-552df4d9817f",
   "metadata": {},
   "source": [
    "Finally we have out approximated adjacency matrix $\\hat{A}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "76b41959-5f21-4eb2-b63f-6e1fc3677669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8928, 0.4491, 0.5277,  ..., 0.5983, 0.8111, 0.7745],\n",
       "        [0.4491, 0.9266, 0.8993,  ..., 0.5041, 0.6885, 0.6491],\n",
       "        [0.5277, 0.8993, 0.9317,  ..., 0.4956, 0.8315, 0.7850],\n",
       "        ...,\n",
       "        [0.5983, 0.5041, 0.4956,  ..., 0.8586, 0.5083, 0.5493],\n",
       "        [0.8111, 0.6885, 0.8315,  ..., 0.5083, 0.9305, 0.8997],\n",
       "        [0.7745, 0.6491, 0.7850,  ..., 0.5493, 0.8997, 0.8702]],\n",
       "       device='mps:0', grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = model.encode (test_data.x, test_data.edge_index)\n",
    "Ahat = torch.sigmoid(z @ z.T)\n",
    "Ahat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322b3025-3a8b-4066-920b-f2699c203ee4",
   "metadata": {},
   "source": [
    "Training a VGAE is fast and outputs are easily understandable, however we know that GCNs are not the most expressive layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9642df45-c755-40a2-8320-2222ef5a4f77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
