{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65dc3dbd-e49b-4beb-83eb-4ef7aaa2351a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from CIR import get_CIR\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "from simulation import Simulation\n",
    "from torch.utils.data import TensorDataset, Dataset, DataLoader, Subset\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61864721-9f29-410a-a8f7-0a67b5efcc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2ad4f95-552f-4cc9-8eb2-34dc81ef6f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am setting v_0=b, so we start the process in its long-term mean\n",
    "\n",
    "alpha = 0.6\n",
    "b = 0.04\n",
    "sigma = 0.14\n",
    "v_0 = 0.04\n",
    "years = 30\n",
    "gamma = 0.4\n",
    "\n",
    "sim = Simulation(alpha, b, sigma, v_0, years, gamma = gamma, seed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fcbbee6-1323-486d-8d35-953482359ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation horizon:  10950\n",
      "Arrival times:  [    0   380   760  1140  1520  1900  2280  2660  3040  3420  3800  4180\n",
      "  4560  4940  5320  5700  6080  6460  6840  7220  7600  7980  8360  8740\n",
      "  9120  9500  9880 10260 10640]\n"
     ]
    }
   ],
   "source": [
    "# Create a new contract every 380 days\n",
    "arrival_times = np.array([i*380 for i in range(years) if i*368+365 < 365*years])\n",
    "print('Simulation horizon: ', sim.TotPoints)\n",
    "print('Arrival times: ', arrival_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f399165-8e12-4f47-9045-014ac1a63d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Contract:\n",
    "\n",
    "    def __init__(self, t_0, sim):\n",
    "        # contract start time\n",
    "        self.t_0 = int(t_0)\n",
    "        # contract end time\n",
    "        self.T = self.t_0 + 365\n",
    "        self.delta = 1\n",
    "        self.sim = sim\n",
    "\n",
    "    def get_contract_features(self, t):\n",
    "        t = int(t)\n",
    "        contract = np.array([(self.T - self.t_0)/365.,                                  # (T-t)/365\n",
    "                             self.delta,                                                # delta\n",
    "                             self.sim.Price(self.t_0, self.T),                          # p(t_0, T)\n",
    "                             self.sim.Price(t, self.T),                                 # p(t, T)\n",
    "                             np.prod(1+(self.sim.CIRProcess[1:self.t_0 + 1]*(1/365.))), # B_t_0\n",
    "                             self.sim.MarkToMarketPrice(1, self.t_0, t, self.T)])       # V(t)\n",
    "        return contract\n",
    "\n",
    "    def is_active(self, t):\n",
    "        t = int(t)\n",
    "        if t >= self.t_0 and t <= self.T:\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec09e0d-217f-4ba3-9ddd-c18dc2b8c238",
   "metadata": {},
   "source": [
    "# Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f60d2dda-d66b-4c36-a7eb-fcb3a70b7256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create contracts\n",
    "contracts = []\n",
    "for arrival_time in arrival_times:\n",
    "    contract = Contract(arrival_time, sim)\n",
    "    contracts.append(contract)\n",
    "\n",
    "# Compute maximum number of simultaneously active contracts\n",
    "max_n_active_contracts = 0\n",
    "for t in range(sim.TotPoints):\n",
    "    n_active_contracts = np.sum([contract.is_active(t) for contract in contracts])\n",
    "    if n_active_contracts > max_n_active_contracts:\n",
    "        max_n_active_contracts = n_active_contracts\n",
    "\n",
    "print(f\"maximum number of simultaneously active contracts: {max_n_active_contracts}\")\n",
    "\n",
    "# Create dataset (features + target)\n",
    "X = torch.zeros((sim.TotPoints, max_n_active_contracts)) # features\n",
    "y = torch.zeros(sim.TotPoints) # targets\n",
    "\n",
    "\n",
    "for i_time, t in enumerate(range(sim.TotPoints)):\n",
    "    \n",
    "    active_contracts = [contract for contract in contracts if contract.is_active(t)]\n",
    "\n",
    "    \n",
    "    for i_contract, contract in enumerate(active_contracts):\n",
    "        \n",
    "        contract_features = contract.get_contract_features(t)\n",
    "        X[i_time, i_contract*len(contract_features), (i_contract+1)*len(contract_features)] = contract_features\n",
    "        \n",
    "        # The targets are summed across active contracts, so we get the net value across contracts\n",
    "        # (e.g. net variation margin or net value of contracts)\n",
    "        y[i_time] += sim.MarkToMarketPrice(contract.delta, contract.t_0, t, contract.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf05c5c7-1940-47b5-bfd0-b100ffbba27e",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 365 is out of bounds for axis 1 with size 365",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m((i\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m380\u001b[39m), np\u001b[38;5;241m.\u001b[39mminimum((i\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m380\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m364\u001b[39m \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, sim\u001b[38;5;241m.\u001b[39mTotPoints)):\n\u001b[1;32m      9\u001b[0m     arrival_time \u001b[38;5;241m=\u001b[39m get_arrival_time(t)\n\u001b[0;32m---> 10\u001b[0m     contract \u001b[38;5;241m=\u001b[39m prepare_contract(arrival_time, sim, t)\n\u001b[1;32m     12\u001b[0m     X\u001b[38;5;241m.\u001b[39mappend(contract)\n\u001b[1;32m     13\u001b[0m     X_for_simulation\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39marray([arrival_time, arrival_time \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m364\u001b[39m, \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m, in \u001b[0;36mprepare_contract\u001b[0;34m(arrival_time, sim, t)\u001b[0m\n\u001b[1;32m      3\u001b[0m contract[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(arrival_time \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m365\u001b[39m \u001b[38;5;241m-\u001b[39m t)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m365\u001b[39m                                 \u001b[38;5;66;03m#T-t/365 ()   \u001b[39;00m\n\u001b[1;32m      4\u001b[0m contract[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m#np.random.choice ([-1,1])                                   #delta\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m contract[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m sim\u001b[38;5;241m.\u001b[39mPrice(\u001b[38;5;28mint\u001b[39m(arrival_time), \u001b[38;5;28mint\u001b[39m(arrival_time \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m365\u001b[39m))           \u001b[38;5;66;03m#p(t_0, T)    \u001b[39;00m\n\u001b[1;32m      6\u001b[0m contract[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m=\u001b[39m sim\u001b[38;5;241m.\u001b[39mPrice(\u001b[38;5;28mint\u001b[39m(t), \u001b[38;5;28mint\u001b[39m(arrival_time \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m365\u001b[39m))                      \u001b[38;5;66;03m#p(t, T)      \u001b[39;00m\n\u001b[1;32m      7\u001b[0m contract[\u001b[38;5;241m4\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mprod(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m+\u001b[39m(sim\u001b[38;5;241m.\u001b[39mCIRProcess[\u001b[38;5;241m0\u001b[39m:arrival_time\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m365\u001b[39m))             \u001b[38;5;66;03m#B_t_0.       \u001b[39;00m\n",
      "File \u001b[0;32m~/ownCloud2/main/papers/generative models of fin nets/Generative-models-for-financial-networks/NodeRegression/simulation.py:94\u001b[0m, in \u001b[0;36mSimulation.Price\u001b[0;34m(self, t, T, r)\u001b[0m\n\u001b[1;32m     91\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mCIRProcess[t]\n\u001b[1;32m     93\u001b[0m closest_index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmin(np\u001b[38;5;241m.\u001b[39mabs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mr_grid\u001b[38;5;241m-\u001b[39mr))\n\u001b[0;32m---> 94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mPriceMatrix[closest_index, tau]\n",
      "\u001b[0;31mIndexError\u001b[0m: index 365 is out of bounds for axis 1 with size 365"
     ]
    }
   ],
   "source": [
    "# Old code (written by Matteo, before Feb 15)\n",
    "\n",
    "# def prepare_contract(arrival_time, sim, t):\n",
    "#     contract = np.zeros(6)\n",
    "#     contract[0] = int(arrival_time + 365 - t)/365                                 #(T-t)/365 ()   \n",
    "#     contract[1] = +1 #np.random.choice ([-1,1])                                   #delta\n",
    "#     contract[2] = sim.Price(int(arrival_time), int(arrival_time + 365))           #p(t_0, T)    \n",
    "#     contract[3] = sim.Price(int(t), int(arrival_time + 365))                      #p(t, T)      \n",
    "#     contract[4] = np.prod(1+(sim.CIRProcess[0:arrival_time+1]*1/365))             #B_t_0.       \n",
    "#     contract[5] = sim.MarkToMarketPrice(+1, arrival_time, t, arrival_time + 365)  #V(t) \n",
    "#     return contract\n",
    "    \n",
    "# def get_arrival_time(t):\n",
    "#     return (t//380)*380\n",
    "\n",
    "# X = []\n",
    "# #I need an auxiliary array that contains (t_0, T, delta) so that i can use `Simulation` methods to compute the targets M_t\n",
    "# X_for_simulation = []\n",
    "\n",
    "# for i in range(years):\n",
    "    \n",
    "#     for t in range((i*380), np.minimum((i*380) + 364 +1, sim.TotPoints)):\n",
    "        \n",
    "#         arrival_time = get_arrival_time(t)\n",
    "#         contract = prepare_contract(arrival_time, sim, t)\n",
    "        \n",
    "#         X.append(contract)\n",
    "#         X_for_simulation.append(np.array([arrival_time, arrival_time + 364, +1]))\n",
    "    \n",
    "#     for i in range(np.minimum((i*380) + 364, sim.TotPoints), np.minimum(((i+1) * 380) - 1, sim.TotPoints)):\n",
    "        \n",
    "#         X.append(np.zeros((6)))\n",
    "#         X_for_simulation.append(np.zeros((3)))\n",
    "\n",
    "\n",
    "# print('Len X: ', len(X))\n",
    "# print('Len auxiliary X: ', len(X_for_simulation))\n",
    "\n",
    "\n",
    "# #Let's put them into tensors\n",
    "# X = torch.tensor(np.stack(X))\n",
    "# X_for_simulation = torch.tensor(np.stack(X_for_simulation))\n",
    "\n",
    "\n",
    "# #Define targets\n",
    "# targets_vt = np.zeros((len(X)))   #Contains V(t) for t\\in [0, sim.totPoints -1]\n",
    "# #targets_vt_1 = np.zeros((len(X)-1)) #Contains V(t+1) for t\\in [0, sim.totPoints]\n",
    "# #targets_mt_1 = np.zeros((len(X)-1)) #Contains M(t+1) for t\\in [0, sim.totPoints]\n",
    "\n",
    "\n",
    "# #Fill targets\n",
    "# for i in range(years):\n",
    "    \n",
    "#     start_index = (i * 380)\n",
    "#     end_index = np.minimum((i*380) + 364 + 1, sim.TotPoints)\n",
    "    \n",
    "#     vt = np.asarray([sim.MarkToMarketPrice(+1, int(X_for_simulation[t,0]), t, int(X_for_simulation[t,1])) for t in range((i * 380), np.minimum((i*380) + 364 +1, sim.TotPoints))])\n",
    "#     #vt1 = np.asarray([sim.MarkToMarketPrice(+1, int(X_for_simulation[t+1,0]), t+1, int(X_for_simulation[t+1,1])) for t in range((i * 380), np.minimum((i*380) + 364 +1, sim.TotPoints-1))])\n",
    "#     #mt1 = np.asarray([sim.GetInstantContractMarginValue(t+1, X_for_simulation[t+1]) for t in range((i * 380), np.minimum((i*380) + 364 +1 , sim.TotPoints-1))])\n",
    "\n",
    "#     #targets_mt_1[ start_index : end_index] = mt1\n",
    "#     targets_vt[ start_index : end_index] = vt\n",
    "#     #targets_vt_1[ start_index : end_index] = vt1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e051f761-ae6d-4381-9381-1a22dbd71033",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y, label='$V(t)$')\n",
    "plt.legend()\n",
    "plt.axhline(0, c='red')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b16b98-79ef-4868-baa3-df932f1113e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X will contain X(t) for t \\in [0, sim.totPoints]\n",
    "X_data = X\n",
    "training_index = int(0.8 * X_data.shape[0])\n",
    "print('Features shape: ', X_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352b75fa-e737-47f7-84d2-a9c3f5022ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For scaling the targets\n",
    "def scale_target(target, training_index):\n",
    "    \"\"\"\n",
    "    Scales and reshape the tensor so that it has shape [sim.totPoints -1 , 1]\n",
    "    \"\"\"\n",
    "\n",
    "    target = torch.tensor(target).reshape(-1,1)\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(target[:training_index].cpu())\n",
    "    scaler.scale_ /= 1.25\n",
    "\n",
    "    target = scaler.transform(target.cpu())\n",
    "    return torch.tensor(target).to(torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06641ed-8dd8-4e09-a971-9dfcd4b16fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale the targets\n",
    "targets_vt = scale_target(targets_vt, training_index)\n",
    "#targets_vt_1 = scale_target(targets_vt_1, training_index)\n",
    "#targets_mt_1 = scale_target(targets_mt_1, training_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef28aebf-6afa-4422-b850-6fe2be858457",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define interest rate process and accrued process\n",
    "CIRProcess = sim.CIRProcess\n",
    "B_t = np.asarray([np.prod(1+(CIRProcess[0:t]*1/365)) for t in range(1,len(CIRProcess)+1)])\n",
    "B_t = torch.tensor(B_t.reshape(-1,1)).to(torch.float32).to(device)\n",
    "CIRProcess = torch.tensor(sim.CIRProcess.reshape(-1,1)).to(torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a984b4-edea-47a2-a2ea-dbba118297cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concat in the feauture matrix\n",
    "X_data = X_data.to(torch.float32).to(device)\n",
    "X_data = torch.cat([X_data, B_t], axis = 1).to(device)\n",
    "print('X_data.shape: ', X_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e234600-8c9c-421b-9b66-003c05987250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate training and test set 0.8 - 0.2\n",
    "train, test = X_data[:training_index, :], X_data[training_index:, :]\n",
    "CIR_train, CIR_test = CIRProcess[:training_index], CIRProcess[training_index:]\n",
    "\n",
    "#Targets training and test set\n",
    "targets_vt_train, targets_vt_test = targets_vt[:training_index], targets_vt[training_index:]\n",
    "#targets_vt_1_train, targets_vt_1_test = targets_vt_1[:training_index], targets_vt_1[training_index:]\n",
    "#targets_mt_1_train, targets_mt_1_test = targets_mt_1[:training_index], targets_mt_1[training_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be7f0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_windows(features, r, targets, lookback):\n",
    "    \"\"\"\n",
    "    Windows the dataset\n",
    "    \"\"\"\n",
    "\n",
    "    n_samples = features.shape[0] - lookback\n",
    "\n",
    "    X_data = torch.zeros(n_samples, lookback, features.shape[1])\n",
    "    y_data = torch.zeros(n_samples, 1)\n",
    "    r_data = torch.zeros(n_samples, 1)\n",
    "\n",
    "    for i_sample in range(n_samples):\n",
    "\n",
    "        X_data[i_sample, :] = features[i_sample : i_sample + lookback]   #it takes data in [i_sample, i_sample+lookback)\n",
    "        y_data[i_sample, 0] = targets[i_sample + lookback]               #it takes [i_sample + lookback] which is +1 time shifted w.r.t. the feature set\n",
    "        r_data[i_sample, 0] = r[i_sample + lookback]\n",
    "    \n",
    "    return X_data.to(torch.float32).to(device), y_data.to(torch.float32).to(device), r_data.to(torch.float32).to(device)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc288f61-9961-4124-884b-c3d25941b4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookback = 10\n",
    "\n",
    "#Windowing slicing - TRAIN\n",
    "X_train, y_vt_train, r_train = create_windows(train, CIR_train, targets_vt_train, lookback=lookback)\n",
    "\n",
    "#_, y_vt_1_train, _ = create_dataset_all_sequence(train, CIR_train, targets_vt_1_train, lookback=lookback)\n",
    "#_, y_mt_1_train, _ = create_dataset_all_sequence(train, CIR_train, targets_mt_1_train, lookback=lookback)\n",
    "\n",
    "#Windowing slicing - TEST\n",
    "X_test, y_vt_test, r_test = create_windows(test, CIR_test, targets_vt_test, lookback=lookback)\n",
    "\n",
    "#_, y_vt_1_test, _ = create_dataset_all_sequence(test, CIR_test, targets_vt_1_test, lookback=lookback)\n",
    "#_, y_mt_1_test, _ = create_dataset_all_sequence(test, CIR_test, targets_mt_1_test, lookback=lookback)\n",
    "\n",
    "#Print out some shapes for User friendlyness\n",
    "print(f'Training features: {X_train.shape}, test features: {X_test.shape}')\n",
    "print('\\n')\n",
    "print(f'Training V(t): {y_vt_train.shape}, test V(t): {y_vt_test.shape}')\n",
    "print(f'Training r(t): {r_train.shape}, test r(t+1): {r_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea09992e-c767-4ea0-8a0a-d26bf4afbc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The actual target we are going to compute the loss on:\n",
    "y_train = y_vt_train\n",
    "y_test = y_vt_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91628ca0-4a63-4848-bad5-9d465b2f3ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the pytorch datasets and dataloaders\n",
    "train_dataset = TensorDataset(X_train.to(device), y_train.to(device), r_train.to(device))\n",
    "test_dataset = TensorDataset(X_test.to(device), y_test.to(device), r_test.to(device))\n",
    "\n",
    "loader = DataLoader(train_dataset, shuffle=True, batch_size=500)\n",
    "loader_test = DataLoader(test_dataset, shuffle=True, batch_size = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8efc0b6-5b6d-4e45-bfed-284abca37f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the model\n",
    "class model(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(model, self).__init__()\n",
    "\n",
    "        input_size = 7\n",
    "        lstm_hidden_size = 15\n",
    "        lstm_n_layers = 1\n",
    "        regressor_hidden_size = 256\n",
    "        self.name=regressor_hidden_size\n",
    "\n",
    "        self.lstm = torch.nn.LSTM(input_size=input_size, \n",
    "                             hidden_size=lstm_hidden_size, \n",
    "                             num_layers=lstm_n_layers)\n",
    "        \n",
    "        #Il +1 è perchè facciamo il concat con il reference interest rate\n",
    "        self.regressor = nn.Sequential(nn.Linear(lstm_hidden_size+1, regressor_hidden_size),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Linear(regressor_hidden_size, 1))\n",
    "        \n",
    "        self.reset_parameters()\n",
    "\n",
    "    def forward(self, x, r):\n",
    "\n",
    "        lstm_hidden, _ = self.lstm(x)\n",
    "        return self.regressor(torch.squeeze(torch.cat([lstm_hidden[:,-1,:], r],dim=1)))\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "\n",
    "        self.lstm.reset_parameters()\n",
    "        for layer in [self.regressor]:\n",
    "            if hasattr(layer, 'reset_parameters'):\n",
    "                layer.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9aaf12-22df-4b54-8604-674fa21f4dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's get towards the training:\n",
    "\n",
    "lr = 1e-2                          #Learning rate\n",
    "criterion = nn.MSELoss()           #Loss function\n",
    "\n",
    "#Define the model\n",
    "mymodel = model().to(device)    \n",
    "\n",
    "#optimizer & scheduler\n",
    "optimizer = torch.optim.Adam(mymodel.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[100*i for i in range(100)], gamma=0.97)\n",
    "\n",
    "n_epochs = 20000                   #Number of epochs\n",
    "\n",
    "#Early stopping parameters\n",
    "patience = 30                      #Number of consecutive epochs to wait for improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d073f1e-fbeb-43b7-8179-03ef9b01a4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the model\n",
    "mymodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2554d4b0-3f13-456a-8027-ce64b1389fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_epoch(loader, model, criterion, optimizer, training=True):\n",
    "    \"\"\"\n",
    "    Trains the model over the batches for an epoch\n",
    "    \"\"\"\n",
    "    \n",
    "    #Instantiate a temp variable that tracks the average loss for the batches\n",
    "    temp_loss = 0\n",
    "\n",
    "    #Loop over data batches\n",
    "    for X_batch, y_batch, r_batch in loader:\n",
    "\n",
    "        #.forward() method of the model\n",
    "        y_pred = model(X_batch, r_batch)\n",
    "\n",
    "        #Compute the loss\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "\n",
    "        #If we are actually training the model instead of permorming validation\n",
    "        if training:\n",
    "\n",
    "            #Backpropagation\n",
    "            loss.backward()\n",
    "    \n",
    "            #Optimizer step\n",
    "            optimizer.step() \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        #Track the batch loss\n",
    "        temp_loss += loss.item()\n",
    "\n",
    "    #Take the average loss over the batches\n",
    "    return temp_loss / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212d257f-5a48-4cfe-828c-d563b271454e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Early stopping class\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_score = 10\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "    \n",
    "        if val_loss > self.best_score:\n",
    "\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "\n",
    "            self.best_score = val_loss\n",
    "            self.save_checkpoint(model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, model):\n",
    "        torch.save(model.state_dict(), f'temp_state_dict{mymodel.name}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199c0302-dfef-4642-91c2-48a34f92a681",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define two lists to store training record\n",
    "training_loss = []\n",
    "validation_loss = []\n",
    "lrs = []\n",
    "\n",
    "#Define a tqdm loop to get a nice progress bar\n",
    "loop = tqdm(range(n_epochs))\n",
    "\n",
    "#Define an early stopping object\n",
    "early_stopping = EarlyStopping(patience)\n",
    "\n",
    "for epoch in loop:\n",
    "\n",
    "    #Set model in training mode\n",
    "    mymodel.train()\n",
    "\n",
    "    #Perform an epoch of training\n",
    "    train_loss = do_epoch(loader, mymodel, criterion, optimizer)\n",
    "\n",
    "    #Scheduler step\n",
    "    scheduler.step()\n",
    "\n",
    "    #Track the average over the batches\n",
    "    training_loss.append(train_loss)\n",
    "\n",
    "    \n",
    "    #Validation every 50 epochs\n",
    "    if epoch % 50 ==0:\n",
    "\n",
    "        with torch.no_grad():\n",
    "            #Set the model in eval mod\n",
    "            mymodel.eval()\n",
    "\n",
    "            test_loss = do_epoch(loader_test, mymodel, criterion, optimizer, training=False)\n",
    "\n",
    "            #Track the average loss over the batches\n",
    "            validation_loss.append(test_loss)\n",
    "\n",
    "        #Check early stopping\n",
    "        early_stopping(validation_loss[-1], mymodel)\n",
    "        if early_stopping.early_stop:\n",
    "\n",
    "            #Load the best set of parameters\n",
    "            mymodel.load_state_dict(torch.load(f'temp_state_dict{mymodel.name}.pt'))\n",
    "            print(f\"Early stopping at epoch {epoch}.\")\n",
    "            break\n",
    "\n",
    "    lrs.append(optimizer.param_groups[0][\"lr\"])\n",
    "            \n",
    "    #Give informations in the loop\n",
    "    loop.set_postfix(loss = train_loss, val_loss = test_loss, best_val_loss = early_stopping.best_score, counter=early_stopping.counter, lr= lrs[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9923e8c-2f99-418d-ae64-03c26049650b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot training record & learning rate schedule\n",
    "\n",
    "plt.figure(figsize=(8,3))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(training_loss, label='Train')\n",
    "val_epochs= np.linspace(0, len(training_loss), num=len(validation_loss))\n",
    "plt.plot(val_epochs, validation_loss, label='Val')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('log(MSE)')\n",
    "plt.title('Training ')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(lrs)\n",
    "plt.grid()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('lr')\n",
    "plt.title('Learning rate')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de71ed94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Makes the predictions\n",
    "def predictions(dataset, model):\n",
    "\n",
    "    dataloader = DataLoader(dataset, shuffle=False, batch_size=1)\n",
    "\n",
    "    y_preds = torch.zeros(len(dataloader))\n",
    "    y_trues = torch.zeros(len(dataloader))\n",
    "    for i_sample, (X, y, r) in enumerate(dataloader):\n",
    "        with torch.no_grad():\n",
    "            y_preds[i_sample] = model(X,r).cpu()\n",
    "            y_trues[i_sample] = y.cpu()\n",
    "            \n",
    "    return y_trues.numpy(), y_preds.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32b0591-2254-4eb1-8855-e6e97965d685",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the predictions\n",
    "train_labels, train_preds = predictions(train_dataset, mymodel)\n",
    "test_labels, test_predictions = predictions(test_dataset, mymodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed10709f-fd4f-406f-90fb-c7dd80e3cc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot predictions\n",
    "plt.figure(figsize=(6,3), dpi=300)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(test_labels, label='$V(t+1) label$')\n",
    "plt.plot(test_predictions, label='Prediction')\n",
    "plt.xlim(100,200)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.title('Non-shifted')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(test_labels[:-1], label='$V(t+1) label$')\n",
    "plt.plot(test_predictions[1:], label='Prediction')\n",
    "plt.xlim(100,200)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.title('Shifted')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec180788",
   "metadata": {},
   "source": [
    "If I try to compute the loss between targets and labels i find, as expected, the same best val loss I observed during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68aab35",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion(torch.tensor(test_labels), torch.tensor(test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120c3775",
   "metadata": {},
   "source": [
    "However, If i shift the arrays I find a better loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262bc29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion(torch.tensor(test_labels[:-1]), torch.tensor(test_predictions[1:]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
