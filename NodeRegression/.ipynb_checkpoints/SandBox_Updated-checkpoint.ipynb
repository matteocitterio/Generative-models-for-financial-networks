{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "65dc3dbd-e49b-4beb-83eb-4ef7aaa2351a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from CIR import get_CIR\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "from simulation import Simulation\n",
    "from torch.utils.data import TensorDataset, Dataset, DataLoader, Subset\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "61864721-9f29-410a-a8f7-0a67b5efcc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "c2ad4f95-552f-4cc9-8eb2-34dc81ef6f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am setting v_0=b, so we start the process in its long-term mean\n",
    "\n",
    "alpha = 0.6\n",
    "b = 0.04\n",
    "sigma = 0.14\n",
    "v_0 = 0.04\n",
    "years = 30\n",
    "gamma = 0.4\n",
    "\n",
    "sim = Simulation(alpha, b, sigma, v_0, years, gamma = gamma, seed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "1fcbbee6-1323-486d-8d35-953482359ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation horizon:  10950\n",
      "Arrival times:  [    0   380   760  1140  1520  1900  2280  2660  3040  3420  3800  4180\n",
      "  4560  4940  5320  5700  6080  6460  6840  7220  7600  7980  8360  8740\n",
      "  9120  9500  9880 10260 10640]\n"
     ]
    }
   ],
   "source": [
    "# Create a new contract every 380 days\n",
    "arrival_times = np.array([i*380 for i in range(years) if i*380 < 365*years])\n",
    "print('Simulation horizon: ', sim.TotPoints)\n",
    "print('Arrival times: ', arrival_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "2f399165-8e12-4f47-9045-014ac1a63d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Contract:\n",
    "\n",
    "    def __init__(self, t_0, sim):\n",
    "        # contract start time\n",
    "        self.t_0 = int(t_0)\n",
    "        # contract end time\n",
    "        self.T = self.t_0 + 365\n",
    "        self.delta = 1.\n",
    "        self.sim = sim\n",
    "\n",
    "    def get_contract_features(self, t):\n",
    "        t = int(t)\n",
    "        contract = torch.tensor([(self.T - t)/365.,                                     # (T-t)/365\n",
    "                             self.sim.Price(self.t_0, self.T),                          # p(t_0, T)\n",
    "                             self.sim.Price(t, self.T),                                 # p(t, T)\n",
    "                             self.sim.B(self.t_0),                                      # B_t_0\n",
    "                             self.sim.B(t),                                             # B_t\n",
    "                             self.sim.MarkToMarketPrice(1, self.t_0, t, self.T)])       # V(t)\n",
    "        return contract\n",
    "\n",
    "    def is_active(self, t):\n",
    "        t = int(t)\n",
    "        if t >= self.t_0 and t <= self.T:\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec09e0d-217f-4ba3-9ddd-c18dc2b8c238",
   "metadata": {},
   "source": [
    "# Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "f60d2dda-d66b-4c36-a7eb-fcb3a70b7256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of simultaneously active contracts: 1\n"
     ]
    }
   ],
   "source": [
    "# Create contracts\n",
    "contracts = []\n",
    "for arrival_time in arrival_times:\n",
    "    contract = Contract(arrival_time, sim)\n",
    "    contracts.append(contract)\n",
    "\n",
    "# Compute maximum number of simultaneously active contracts\n",
    "max_n_active_contracts = 0\n",
    "for t in range(sim.TotPoints):\n",
    "    n_active_contracts = np.sum([contract.is_active(t) for contract in contracts])\n",
    "    if n_active_contracts > max_n_active_contracts:\n",
    "        max_n_active_contracts = n_active_contracts\n",
    "\n",
    "print(f\"Max number of simultaneously active contracts: {max_n_active_contracts}\")\n",
    "\n",
    "# Create dataset (features + target)\n",
    "n_contract_features = len(contracts[0].get_contract_features(0))\n",
    "# features\n",
    "X = torch.zeros((sim.TotPoints, max_n_active_contracts*n_contract_features)) \n",
    "# targets\n",
    "y = torch.zeros(sim.TotPoints) \n",
    "\n",
    "for i_time, t in enumerate(range(sim.TotPoints-1)):\n",
    "    active_contracts = [contract for contract in contracts if contract.is_active(t)]\n",
    "    for i_contract, contract in enumerate(active_contracts):\n",
    "        \n",
    "        contract_features = contract.get_contract_features(t)\n",
    "        X[i_time, i_contract*len(contract_features) : (i_contract+1)*len(contract_features)] = contract_features\n",
    "        \n",
    "        # The targets are summed across active contracts, so we get the net value across contracts\n",
    "        # (e.g. net variation margin or net value of contracts)\n",
    "        y[i_time] += sim.MarkToMarketPrice(contract.delta, contract.t_0, t, contract.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "bf05c5c7-1940-47b5-bfd0-b100ffbba27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old code (written by Matteo, before Feb 15)\n",
    "\n",
    "# def prepare_contract(arrival_time, sim, t):\n",
    "#     contract = np.zeros(6)\n",
    "#     contract[0] = int(arrival_time + 365 - t)/365                                 #(T-t)/365 ()   \n",
    "#     contract[1] = +1 #np.random.choice ([-1,1])                                   #delta\n",
    "#     contract[2] = sim.Price(int(arrival_time), int(arrival_time + 365))           #p(t_0, T)    \n",
    "#     contract[3] = sim.Price(int(t), int(arrival_time + 365))                      #p(t, T)      \n",
    "#     contract[4] = np.prod(1+(sim.CIRProcess[0:arrival_time+1]*1/365))             #B_t_0.       \n",
    "#     contract[5] = sim.MarkToMarketPrice(+1, arrival_time, t, arrival_time + 365)  #V(t) \n",
    "#     return contract\n",
    "    \n",
    "# def get_arrival_time(t):\n",
    "#     return (t//380)*380\n",
    "\n",
    "# X = []\n",
    "# #I need an auxiliary array that contains (t_0, T, delta) so that i can use `Simulation` methods to compute the targets M_t\n",
    "# X_for_simulation = []\n",
    "\n",
    "# for i in range(years):\n",
    "    \n",
    "#     for t in range((i*380), np.minimum((i*380) + 364 +1, sim.TotPoints)):\n",
    "        \n",
    "#         arrival_time = get_arrival_time(t)\n",
    "#         contract = prepare_contract(arrival_time, sim, t)\n",
    "        \n",
    "#         X.append(contract)\n",
    "#         X_for_simulation.append(np.array([arrival_time, arrival_time + 364, +1]))\n",
    "    \n",
    "#     for i in range(np.minimum((i*380) + 364, sim.TotPoints), np.minimum(((i+1) * 380) - 1, sim.TotPoints)):\n",
    "        \n",
    "#         X.append(np.zeros((6)))\n",
    "#         X_for_simulation.append(np.zeros((3)))\n",
    "\n",
    "\n",
    "# print('Len X: ', len(X))\n",
    "# print('Len auxiliary X: ', len(X_for_simulation))\n",
    "\n",
    "\n",
    "# #Let's put them into tensors\n",
    "# X = torch.tensor(np.stack(X))\n",
    "# X_for_simulation = torch.tensor(np.stack(X_for_simulation))\n",
    "\n",
    "\n",
    "# #Define targets\n",
    "# targets_vt = np.zeros((len(X)))   #Contains V(t) for t\\in [0, sim.totPoints -1]\n",
    "# #targets_vt_1 = np.zeros((len(X)-1)) #Contains V(t+1) for t\\in [0, sim.totPoints]\n",
    "# #targets_mt_1 = np.zeros((len(X)-1)) #Contains M(t+1) for t\\in [0, sim.totPoints]\n",
    "\n",
    "\n",
    "# #Fill targets\n",
    "# for i in range(years):\n",
    "    \n",
    "#     start_index = (i * 380)\n",
    "#     end_index = np.minimum((i*380) + 364 + 1, sim.TotPoints)\n",
    "    \n",
    "#     vt = np.asarray([sim.MarkToMarketPrice(+1, int(X_for_simulation[t,0]), t, int(X_for_simulation[t,1])) for t in range((i * 380), np.minimum((i*380) + 364 +1, sim.TotPoints))])\n",
    "#     #vt1 = np.asarray([sim.MarkToMarketPrice(+1, int(X_for_simulation[t+1,0]), t+1, int(X_for_simulation[t+1,1])) for t in range((i * 380), np.minimum((i*380) + 364 +1, sim.TotPoints-1))])\n",
    "#     #mt1 = np.asarray([sim.GetInstantContractMarginValue(t+1, X_for_simulation[t+1]) for t in range((i * 380), np.minimum((i*380) + 364 +1 , sim.TotPoints-1))])\n",
    "\n",
    "#     #targets_mt_1[ start_index : end_index] = mt1\n",
    "#     targets_vt[ start_index : end_index] = vt\n",
    "#     #targets_vt_1[ start_index : end_index] = vt1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "352b75fa-e737-47f7-84d2-a9c3f5022ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #For scaling the targets\n",
    "# def scale_target(target, training_index):\n",
    "#     \"\"\"\n",
    "#     Scales and reshape the tensor so that it has shape [sim.totPoints -1 , 1]\n",
    "#     \"\"\"\n",
    "\n",
    "#     target = target.clone().detach().reshape(-1,1)\n",
    "    \n",
    "#     scaler = MinMaxScaler()\n",
    "#     scaler.fit(target[:training_index].cpu())\n",
    "#     scaler.scale_ /= 1.25\n",
    "\n",
    "#     target = scaler.transform(target.cpu())\n",
    "#     return torch.tensor(target).to(torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "a06641ed-8dd8-4e09-a971-9dfcd4b16fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "\n",
    "training_index = int(0.8 * X.shape[0])\n",
    "\n",
    "CIRProcess = torch.tensor(sim.CIRProcess.reshape(-1,1)).to(torch.float32).to(device)\n",
    "\n",
    "y_train = y[:training_index]\n",
    "X_train = X[:training_index, :]\n",
    "CIR_train = CIRProcess[:training_index]\n",
    "\n",
    "y_test = y[training_index:]\n",
    "X_test = X[training_index:, :]\n",
    "CIR_test = CIRProcess[training_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "4be7f0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_windows(features, targets, r, lookback):\n",
    "    \"\"\"\n",
    "    Windows the dataset\n",
    "    \"\"\"\n",
    "    n_samples = features.shape[0] - lookback\n",
    "\n",
    "    X_data = torch.zeros(n_samples, lookback, features.shape[1])\n",
    "    y_data = torch.zeros(n_samples, 1)\n",
    "    r_data = torch.zeros(n_samples, 1)\n",
    "\n",
    "    for i_sample in range(n_samples):\n",
    "\n",
    "        X_data[i_sample, :] = features[i_sample : i_sample + lookback]   #it takes data in [i_sample, i_sample+lookback)\n",
    "        y_data[i_sample, 0] = targets[i_sample + lookback]               #it takes [i_sample + lookback] which is +1 time shifted w.r.t. the feature set\n",
    "        r_data[i_sample, 0] = r[i_sample + lookback]\n",
    "        \n",
    "    return X_data.to(torch.float32).to(device), y_data.to(torch.float32).to(device), r_data.to(torch.float32).to(device)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "dc288f61-9961-4124-884b-c3d25941b4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice dataset into windows\n",
    "\n",
    "lookback = 5\n",
    "X_train, y_train, r_train = create_windows(X_train, y_train, CIR_train, lookback=lookback)\n",
    "X_test, y_test, r_test = create_windows(X_test, y_test, CIR_test, lookback=lookback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "4817dff8-85c2-42cd-bccc-38c1bbc9e4a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X_train[:, -1, -1], 'bx', label='Feature V(t) at time t')\n",
    "plt.plot(y_train, 'r.', label='Target V(t+1) at time t')\n",
    "plt.xlim([0, 10])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "91628ca0-4a63-4848-bad5-9d465b2f3ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the pytorch datasets and dataloaders\n",
    "train_dataset = TensorDataset(X_train.to(device), y_train.to(device), r_train.to(device))\n",
    "test_dataset = TensorDataset(X_test.to(device), y_test.to(device), r_test.to(device))\n",
    "\n",
    "loader = DataLoader(train_dataset, shuffle=True, batch_size=1000)\n",
    "loader_test = DataLoader(test_dataset, shuffle=True, batch_size = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "b8efc0b6-5b6d-4e45-bfed-284abca37f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the model\n",
    "class model(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(model, self).__init__()\n",
    "\n",
    "        input_size = 6\n",
    "        lstm_hidden_size = 30\n",
    "        lstm_n_layers = 1\n",
    "        regressor_hidden_size = 128\n",
    "        self.name=regressor_hidden_size\n",
    "\n",
    "        self.lstm = torch.nn.LSTM(input_size=input_size, \n",
    "                             hidden_size=lstm_hidden_size, \n",
    "                             num_layers=lstm_n_layers)\n",
    "        \n",
    "        #Il +1 è perchè facciamo il concat con il reference interest rate\n",
    "        self.regressor = nn.Sequential(nn.Linear(lstm_hidden_size+1, regressor_hidden_size),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Linear(regressor_hidden_size, regressor_hidden_size),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Linear(regressor_hidden_size, 1))\n",
    "        \n",
    "        self.reset_parameters()\n",
    "\n",
    "    def forward(self, x, r):\n",
    "\n",
    "        lstm_hidden, _ = self.lstm(x)\n",
    "        return self.regressor(torch.squeeze(torch.cat([lstm_hidden[:,-1,:], 1.+r],dim=1)))\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "\n",
    "        self.lstm.reset_parameters()\n",
    "        for layer in [self.regressor]:\n",
    "            if hasattr(layer, 'reset_parameters'):\n",
    "                layer.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "bf9aaf12-22df-4b54-8604-674fa21f4dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's get towards the training:\n",
    "\n",
    "lr = 1e-1                         #Learning rate\n",
    "criterion = nn.MSELoss()           #Loss function\n",
    "\n",
    "#Define the model\n",
    "mymodel = model().to(device)    \n",
    "\n",
    "#optimizer & scheduler\n",
    "optimizer = torch.optim.Adam(mymodel.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[100*i for i in range(100)], gamma=0.8)\n",
    "\n",
    "n_epochs = 1000                   #Number of epochs\n",
    "\n",
    "#Early stopping parameters\n",
    "patience = 30                      #Number of consecutive epochs to wait for improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "9d073f1e-fbeb-43b7-8179-03ef9b01a4e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model(\n",
       "  (lstm): LSTM(6, 30)\n",
       "  (regressor): Sequential(\n",
       "    (0): Linear(in_features=31, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print the model\n",
    "mymodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "2554d4b0-3f13-456a-8027-ce64b1389fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_epoch(loader, model, criterion, optimizer, training=True):\n",
    "    \"\"\"\n",
    "    Trains the model over the batches for an epoch\n",
    "    \"\"\"\n",
    "    \n",
    "    #Instantiate a temp variable that tracks the average loss for the batches\n",
    "    temp_loss = 0\n",
    "\n",
    "    #Loop over data batches\n",
    "    for X_batch, y_batch, r_batch in loader:\n",
    "\n",
    "        #.forward() method of the model\n",
    "        y_pred = model(X_batch, r_batch)\n",
    "\n",
    "        #Compute the loss\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "\n",
    "        #If we are actually training the model instead of permorming validation\n",
    "        if training:\n",
    "\n",
    "            #Backpropagation\n",
    "            loss.backward()\n",
    "    \n",
    "            #Optimizer step\n",
    "            optimizer.step() \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        #Track the batch loss\n",
    "        temp_loss += loss.item()\n",
    "\n",
    "    #Take the average loss over the batches\n",
    "    return temp_loss / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "212d257f-5a48-4cfe-828c-d563b271454e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Early stopping class\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_score = 10\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "    \n",
    "        if val_loss > self.best_score:\n",
    "\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "\n",
    "            self.best_score = val_loss\n",
    "            self.save_checkpoint(model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, model):\n",
    "        torch.save(model.state_dict(), f'temp_state_dict{mymodel.name}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199c0302-dfef-4642-91c2-48a34f92a681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37059a92d1b54c5686af3667ec1abdcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Define two lists to store training record\n",
    "training_loss = []\n",
    "validation_loss = []\n",
    "lrs = []\n",
    "\n",
    "#Define a tqdm loop to get a nice progress bar\n",
    "loop = tqdm(range(n_epochs))\n",
    "\n",
    "#Define an early stopping object\n",
    "early_stopping = EarlyStopping(patience)\n",
    "\n",
    "for epoch in loop:\n",
    "\n",
    "    #Set model in training mode\n",
    "    mymodel.train()\n",
    "\n",
    "    #Perform an epoch of training\n",
    "    train_loss = do_epoch(loader, mymodel, criterion, optimizer)\n",
    "\n",
    "    #Scheduler step\n",
    "    scheduler.step()\n",
    "\n",
    "    #Track the average over the batches\n",
    "    training_loss.append(train_loss)\n",
    "\n",
    "    \n",
    "    #Validation every 50 epochs\n",
    "    if epoch % 50 ==0:\n",
    "\n",
    "        with torch.no_grad():\n",
    "            #Set the model in eval mod\n",
    "            mymodel.eval()\n",
    "\n",
    "            test_loss = do_epoch(loader_test, mymodel, criterion, optimizer, training=False)\n",
    "\n",
    "            #Track the average loss over the batches\n",
    "            validation_loss.append(test_loss)\n",
    "\n",
    "        #Check early stopping\n",
    "        early_stopping(validation_loss[-1], mymodel)\n",
    "        if early_stopping.early_stop:\n",
    "\n",
    "            #Load the best set of parameters\n",
    "            mymodel.load_state_dict(torch.load(f'temp_state_dict{mymodel.name}.pt'))\n",
    "            print(f\"Early stopping at epoch {epoch}.\")\n",
    "            break\n",
    "\n",
    "    lrs.append(optimizer.param_groups[0][\"lr\"])\n",
    "            \n",
    "    #Give informations in the loop\n",
    "    loop.set_postfix(loss = train_loss, val_loss = test_loss, best_val_loss = early_stopping.best_score, counter=early_stopping.counter, lr= lrs[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9923e8c-2f99-418d-ae64-03c26049650b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot training record & learning rate schedule\n",
    "\n",
    "plt.figure(figsize=(8,3))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(training_loss, label='Train')\n",
    "val_epochs= np.linspace(0, len(training_loss), num=len(validation_loss))\n",
    "plt.plot(val_epochs, validation_loss, label='Val')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('log(MSE)')\n",
    "plt.title('Training ')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(lrs)\n",
    "plt.grid()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('lr')\n",
    "plt.title('Learning rate')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de71ed94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Makes the predictions\n",
    "def predictions(dataset, model):\n",
    "\n",
    "    dataloader = DataLoader(dataset, shuffle=False, batch_size=1)\n",
    "\n",
    "    y_preds = torch.zeros(len(dataloader))\n",
    "    y_trues = torch.zeros(len(dataloader))\n",
    "    for i_sample, (X, y, r) in enumerate(dataloader):\n",
    "        with torch.no_grad():\n",
    "            y_preds[i_sample] = model(X,r).cpu()\n",
    "            y_trues[i_sample] = y.cpu()\n",
    "            \n",
    "    return y_trues.numpy(), y_preds.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32b0591-2254-4eb1-8855-e6e97965d685",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the predictions\n",
    "train_labels, train_predictions = predictions(train_dataset, mymodel)\n",
    "test_labels, test_predictions = predictions(test_dataset, mymodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16015c3a-d121-447e-8e69-cb9f8840b6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot predictions (train)\n",
    "plt.figure(figsize=(6,3), dpi=300)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(train_labels, 'r.', label='$V(t+1)$ label')\n",
    "plt.plot(train_predictions, 'bx', label='Prediction')\n",
    "plt.xlim(0,200)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.title('Non-shifted')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(train_labels[:-1], 'r.', label='$V(t+1)$ label')\n",
    "plt.plot(train_predictions[1:], 'bx', label='Prediction')\n",
    "plt.xlim(0,200)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.title('Shifted')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed10709f-fd4f-406f-90fb-c7dd80e3cc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot predictions (test)\n",
    "plt.figure(figsize=(6,3), dpi=300)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(test_labels, 'r.', label='$V(t+1)$ label')\n",
    "plt.plot(test_predictions, 'bx', label='Prediction')\n",
    "#plt.xlim(100,150)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.title('Non-shifted')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(test_labels[:-1], 'r.', label='$V(t+1)$ label')\n",
    "plt.plot(test_predictions[1:], 'bx', label='Prediction')\n",
    "#plt.xlim(100,150)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.title('Shifted')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec180788",
   "metadata": {},
   "source": [
    "If I try to compute the loss between targets and labels i find, as expected, the same best val loss I observed during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d68aab35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.8120e-07)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(torch.tensor(test_labels), torch.tensor(test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120c3775",
   "metadata": {},
   "source": [
    "However, If i shift the arrays I find a better loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "262bc29b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.8145e-07)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(torch.tensor(test_labels[:-1]), torch.tensor(test_predictions[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def992e4-312f-49aa-84e1-20570a29b6d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
