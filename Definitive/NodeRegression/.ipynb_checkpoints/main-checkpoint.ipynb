{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79c7b131-ea58-4569-84f9-a519215b5554",
   "metadata": {},
   "source": [
    "First of all, it is necessary to equip ourselves with the required packages. \n",
    "Please run on your terminal:\n",
    "\n",
    "                                            `pip install -r requirements.txt`\n",
    "\n",
    "I'd suggest creating a separate virtual env to do so just to protect everything else you have on your computer. Unfortunately some nasty packages are required and the operation may take a while. Please consider that the `requirements.txt` list includes only few of these packages and while running the notebook it may happen to install additional packages. If possible, reports this packages and update the list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81b8c2e7-9703-41d8-9585-ae4dec7e82dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from CIR import get_CIR\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "from simulation import Simulation, Contract\n",
    "from torch.utils.data import TensorDataset, Dataset, DataLoader\n",
    "import Sandbox_utils as utils\n",
    "import dataset_managment\n",
    "import model_managment\n",
    "import train_managment\n",
    "import torch_geometric\n",
    "\n",
    "from GCLSTM import GCLSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc21b45-8e08-4b71-a67c-bba61d5cfe53",
   "metadata": {},
   "source": [
    "We will divide our discussion into 2 steps: the first part is model **training**, the second one is related to its evaluation.\n",
    "\n",
    "# Model Fit\n",
    "\n",
    "## First steps\n",
    "\n",
    "First of all we need to fix a 'device' over which we will run our code. I'd suggest using 'cuda' or andother GPU kernel whenever possible, especially when it comes to fitting the model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "553eba21-452e-4be8-b9f7-35037354b328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cpu\n"
     ]
    }
   ],
   "source": [
    "# Fix current device\n",
    "device = (\n",
    "    \"cuda:0\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"      #MacOS\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "#Unccoment here, is just for Matteo's testing \n",
    "device = 'cpu'\n",
    "\n",
    "print('Device: ', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84444133-13ec-4dec-bce5-20d6e20fd22f",
   "metadata": {},
   "source": [
    "It is quite useful to use `argparse` as we can pass a lot of parameters both through a dictionary and a `.yaml` file. Here on the notebook its just a simple dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71822acf-40a7-4da1-9017-f0bf7e465887",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "def dict_to_args(dictionary):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    for key, value in dictionary.items():\n",
    "        parser.add_argument(f'--{key}', type=type(value), default=value)\n",
    "    \n",
    "    return parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c4118d5-13de-464c-b122-9f826ec0805c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of multiple parameters used both during simulation and \n",
    "args = { \n",
    "    'lookback' : 5,                       #Number of historical steps to learn from \n",
    "    'num_nodes' : 5,                      #Number of nodes in the network\n",
    "    'alpha' : 0.6,                        #Duffie et al. parameters\n",
    "    'b' : 0.04,\n",
    "    'sigma' : 0.14,\n",
    "    'v_0' : 0.04,\n",
    "    'gamma' : 3,\n",
    "    'years' : 60,                         #Synthetic dataset time horizon\n",
    "    'steps_ahead' : 5,                    #Prediction horizon\n",
    "    'lstm_hidden_size' : 15,              #Model parameters\n",
    "    'regressor_hidden_size' : 512,\n",
    "    'regressor_hidden_size_2' : 512,\n",
    "    'number_regressor_layers' : 2,\n",
    "    'input_size' : 36,\n",
    "    'contract_size' : 6,\n",
    "    'device': 'cpu',\n",
    "    'batch_size' : 500\n",
    "}\n",
    "\n",
    "args = dict_to_args(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf3b8a3-5cd3-4a8b-9b3e-f971c4324669",
   "metadata": {},
   "source": [
    "## Loading simulation data\n",
    "\n",
    "Now we load both data coming from the simulation of the synthetic model. The so-called benchmark for each node (i.e.) the best theoretical predictor given the interest rate conditioning  and the graph's data (contract features + adjacency matrix) for each step.\n",
    "In order to obtain these quantities, please refer to `todo.ipynb` (MISSING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce5827ab-c1f9-4b4a-bc7c-b0375304f54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_name = '../data/'\n",
    "data_file_name = path_name + f'subgraphs_Duffie_{args.num_nodes}nodes_3gamma.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f50f6892-1cf2-4397-aacf-fab683f723bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving data...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(f'Retrieving data...')\n",
    "    dataset = torch.load(path_name + f'subgraphs_Duffie_{args.num_nodes}nodes_3gamma.pt',  map_location=torch.device(device))\n",
    "    bench = torch.load('../data/y_benchmark_5nodes.pt')\n",
    "    print(f'Done')\n",
    "\n",
    "except:\n",
    "    print('Error: the data file: ',path_name + f'subgraphs_Duffie_{args.num_nodes}nodes_3gamma.pt',' doesnt exist, please run `SimulateNetwork.py`')\n",
    "    raise ValueError\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ca4ca8-879a-44d4-99ce-6571299f1c42",
   "metadata": {},
   "source": [
    "Then we generate the interest rate process with **the same parameters** so that we retain data consistency. We also build a simulation object which will come in handy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13b4a558-09f1-4524-a4cc-3a76d4b39abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate CIR process & simulation\n",
    "sim = Simulation(args.alpha, args.b, args.sigma, args.v_0, args.years, gamma = args.gamma, seed=True)\n",
    "CIRProcess = torch.tensor(sim.CIRProcess.reshape(-1,1)).to(torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fffa55-abaa-46d5-8377-675f2452fab1",
   "metadata": {},
   "source": [
    "Just to be super clear, `dataset` is a list of which each item represent our network for a given day of the simulation horizon. Each item is a `torch_geometric.data` object which stores a graph in terms of its features and the adjacency matrix. For instance, the graph on our 100-th day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8780c9b7-fecb-42e6-bc11-544cccb21831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[5, 168], edge_index=[2, 2], y=[5], r=[1], node_feat=[5], num_nodes=5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e181dc2-d80e-4965-9ab9-582e76607b7d",
   "metadata": {},
   "source": [
    "Where x is the node feature matrix, edge_index the adjacency matrix, y the target, r the interest rate. `node_feat` is the feature for each node representing the 'characteristic' of each node (See Eq.18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ccce8bc9-ccf7-442b-8368-931614d2c9cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 168])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[100].x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b26214-276b-43b4-a8db-54c56b3b7c3e",
   "metadata": {},
   "source": [
    "The shape of `x` is number_of_nodes, number_of_maximum_contracts * n_contract_features], with `number_of_maximum_contracts` referring to the maximum number of simultaneously active contracts throughout the entire simulation horizon, while `n_contract_features` is the length of each contract features ($T-t/365, \\log{p(t_0, T)}, \\log{p(t,T)}, \\log{B(t_0)}, \\log{B(t)}, \\delta_{ij} $).\n",
    "\n",
    "`edge_index` stores the adjacency matrix in a sparse format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f6ef84-5e2a-4fbc-b436-5eb7d78caa3f",
   "metadata": {},
   "source": [
    "bench.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a604b0-8516-4ad5-b275-796b87bfd2f0",
   "metadata": {},
   "source": [
    "`bench` has shape [simulation_horizon, source_nodes, number_of_steps_in_the_future]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b164635-ac48-4f1a-996e-aadcc1cffd50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([21806, 5, 5])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bench.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162eab54-ba0e-4ea0-b4d8-bfad3d72711d",
   "metadata": {},
   "source": [
    "## Data processing\n",
    "\n",
    "We proceed with the **Train/Test** split, which is here set at **0.8/0.2**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb05afa9-3f20-4c96-8fdb-60c4db9de9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "training_index = int(0.8 * len(dataset))\n",
    "\n",
    "#TRAIN\n",
    "train_dataset = dataset[:training_index]\n",
    "\n",
    "#TEST\n",
    "test_dataset = dataset[training_index:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6952e8-8a75-4637-b081-a3ef024bdeb8",
   "metadata": {},
   "source": [
    "We window data as extensively explained in Sec. 3.3.2 and in Fig 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7627cce2-ff6c-447b-9ffe-a287abc19449",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c3e2961-3e5e-4662-a3b8-ed8ab7b19b3e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Slice dataset into windows\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m Contract_train, y_margin_train, r_train, y_bench_train \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mcreate_graph_windows(args, device,cos, \u001b[43mtrain_dataset\u001b[49m)\n\u001b[1;32m      3\u001b[0m Contract_test,y_margin_test, r_test, y_bench_test \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mcreate_graph_windows(args, device,cos, test_dataset)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# Slice dataset into windows\n",
    "Contract_train, y_margin_train, r_train, y_bench_train = utils.create_graph_windows(args, device,cos, train_dataset)\n",
    "Contract_test,y_margin_test, r_test, y_bench_test = utils.create_graph_windows(args, device,cos, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535b8de5-f00a-4555-9882-2eb42216e2f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
